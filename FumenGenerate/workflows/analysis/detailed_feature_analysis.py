#!/usr/bin/env python3
"""
è¯¦ç»†å±•ç¤ºæˆ‘ä»¬è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç‰¹å¾æå–æ–¹æ³•
"""

import numpy as np
import librosa
import os
import zipfile
import json

def demonstrate_feature_extraction_pipeline():
    """æ¼”ç¤ºå®Œæ•´çš„ç‰¹å¾æå–æµç¨‹"""
    print(f"ğŸ”¬ è¯¦ç»†å±•ç¤ºæˆ‘ä»¬çš„ç‰¹å¾æå–æµç¨‹")
    print(f"=" * 60)
    
    # ä½¿ç”¨ä¸€ä¸ªæ ‡å‡†MCZæ–‡ä»¶æ¼”ç¤º
    mcz_path = "trainData/_song_4833.mcz"
    
    try:
        with zipfile.ZipFile(mcz_path, 'r') as mcz:
            # 1. æå–éŸ³é¢‘
            audio_files = [f for f in mcz.namelist() if f.endswith('.ogg')]
            import tempfile
            temp_dir = tempfile.mkdtemp()
            audio_file = audio_files[0]
            mcz.extract(audio_file, temp_dir)
            audio_path = os.path.join(temp_dir, audio_file)
            
            # 2. æå–è°±é¢æ•°æ®
            target_mc = "0/1511697495.mc"
            with mcz.open(target_mc, 'r') as f:
                mc_data = json.loads(f.read().decode('utf-8'))
            
            print(f"ğŸ“ ä½¿ç”¨æ–‡ä»¶: {mcz_path}")
            print(f"ğŸµ éŸ³é¢‘æ–‡ä»¶: {audio_file}")
            print(f"ğŸ¼ è°±é¢æ–‡ä»¶: {target_mc}")
            
            # 3. åŠ è½½éŸ³é¢‘
            y, sr = librosa.load(audio_path, sr=22050)
            duration = len(y) / sr
            
            print(f"\nğŸ“Š éŸ³é¢‘åŸºæœ¬ä¿¡æ¯:")
            print(f"   æ—¶é•¿: {duration:.2f} ç§’")
            print(f"   é‡‡æ ·ç‡: {sr} Hz")
            
            # 4. æå–è°±é¢æ—¶é—´ç‚¹
            notes = mc_data.get('note', [])
            game_notes = [note for note in notes if 'column' in note]
            time_info = mc_data.get('time', [])
            
            if time_info:
                bpm = time_info[0].get('bpm', 156)
                
                # è®¡ç®—æ¯ä¸ªéŸ³ç¬¦çš„æ—¶é—´
                note_times = []
                note_columns = []
                for note in game_notes:
                    beat = note.get('beat', [])
                    column = note.get('column', 0)
                    if len(beat) >= 3:
                        x, y, z = beat[0], beat[1], beat[2]
                        beat_value = x + y / z
                        time_seconds = beat_value * 60 / bpm
                        note_times.append(time_seconds)
                        note_columns.append(column)
                
                note_times = np.array(note_times)
                note_columns = np.array(note_columns)
                
                print(f"\nğŸ¼ è°±é¢ä¿¡æ¯:")
                print(f"   BPM: {bpm:.1f}")
                print(f"   éŸ³ç¬¦æ•°: {len(note_times)}")
                print(f"   æ—¶é—´èŒƒå›´: {note_times.min():.2f} - {note_times.max():.2f} ç§’")
                
                return demonstrate_training_features(y, sr, duration, note_times, note_columns)
                
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        return None

def demonstrate_training_features(y, sr, duration, note_times, note_columns):
    """æ¼”ç¤ºè®­ç»ƒä¸­çš„ç‰¹å¾æå–"""
    print(f"\nğŸ§  è®­ç»ƒç‰¹å¾æå–æ¼”ç¤º:")
    print(f"=" * 40)
    
    # 1. æ—¶é—´çª—å£è®¾ç½®
    window_size = 0.1  # 100æ¯«ç§’çª—å£
    hop_size = 0.05    # 50æ¯«ç§’æ­¥é•¿
    
    print(f"â° æ—¶é—´çª—å£è®¾ç½®:")
    print(f"   çª—å£å¤§å°: {window_size * 1000:.0f} æ¯«ç§’")
    print(f"   æ­¥é•¿: {hop_size * 1000:.0f} æ¯«ç§’")
    
    # 2. ç”Ÿæˆè®­ç»ƒæ ·æœ¬æ—¶é—´ç‚¹
    sample_times = np.arange(0, duration - window_size, hop_size)
    print(f"   è®­ç»ƒæ ·æœ¬æ•°: {len(sample_times)}")
    
    # 3. ä¸ºæ¯ä¸ªæ—¶é—´çª—å£æå–ç‰¹å¾å’Œæ ‡ç­¾
    features_list = []
    labels_list = []
    
    print(f"\nğŸ” ç‰¹å¾æå–è¿‡ç¨‹ (æ˜¾ç¤ºå‰5ä¸ªæ ·æœ¬):")
    
    for i, start_time in enumerate(sample_times[:5]):
        end_time = start_time + window_size
        
        print(f"\n   ğŸ“ æ ·æœ¬ {i+1}: æ—¶é—´ {start_time:.3f} - {end_time:.3f} ç§’")
        
        # æå–è¿™ä¸ªæ—¶é—´çª—å£çš„éŸ³é¢‘ç‰‡æ®µ
        start_frame = int(start_time * sr)
        end_frame = int(end_time * sr)
        audio_segment = y[start_frame:end_frame]
        
        # 4. éŸ³é¢‘ç‰¹å¾æå–
        features = extract_window_features(audio_segment, sr)
        
        print(f"      ğŸµ éŸ³é¢‘ç‰¹å¾:")
        for key, value in features.items():
            if isinstance(value, (int, float)):
                print(f"         {key}: {value:.4f}")
            else:
                print(f"         {key}: {type(value).__name__} {np.array(value).shape}")
        
        # 5. æ ‡ç­¾ç”Ÿæˆ
        label = generate_training_label(start_time, end_time, note_times, note_columns)
        
        print(f"      ğŸ¯ è®­ç»ƒæ ‡ç­¾:")
        print(f"         æœ‰éŸ³ç¬¦: {label['has_note']}")
        if label['has_note']:
            print(f"         é”®ä½: {label['columns']}")
            print(f"         éŸ³ç¬¦æ—¶é—´: {label['note_times']}")
        
        features_list.append(features)
        labels_list.append(label)
    
    # 6. æ€»ç»“ç‰¹å¾å·¥ç¨‹
    print(f"\nğŸ“ˆ ç‰¹å¾å·¥ç¨‹æ€»ç»“:")
    print(f"   â€¢ æ—¶é—´çª—å£åˆ’åˆ†: å°†è¿ç»­éŸ³é¢‘åˆ‡åˆ†ä¸ºå›ºå®šé•¿åº¦ç‰‡æ®µ")
    print(f"   â€¢ éŸ³é¢‘ç‰¹å¾æå–: æ¯ä¸ªç‰‡æ®µæå–å¤šç»´ç‰¹å¾å‘é‡")
    print(f"   â€¢ æ ‡ç­¾å…³è”: æ£€æŸ¥è¯¥æ—¶é—´çª—å£å†…æ˜¯å¦æœ‰è°±é¢éŸ³ç¬¦")
    print(f"   â€¢ å¤šåˆ†ç±»é—®é¢˜: é¢„æµ‹æ˜¯å¦æœ‰éŸ³ç¬¦ + é¢„æµ‹é”®ä½")
    
    return features_list, labels_list

def extract_window_features(audio_segment, sr):
    """ä¸ºéŸ³é¢‘çª—å£æå–ç‰¹å¾"""
    features = {}
    
    if len(audio_segment) == 0:
        # ç©ºéŸ³é¢‘ç‰‡æ®µçš„é»˜è®¤å€¼
        return {
            'rms': 0.0,
            'spectral_centroid': 0.0,
            'zcr': 0.0,
            'mfcc_mean': [0.0] * 13,
            'chroma_mean': [0.0] * 12,
            'tempo_local': 0.0,
            'onset_strength': 0.0
        }
    
    # 1. èƒ½é‡ç‰¹å¾
    rms = librosa.feature.rms(y=audio_segment)[0]
    features['rms'] = np.mean(rms)
    
    # 2. é¢‘è°±ç‰¹å¾
    spectral_centroid = librosa.feature.spectral_centroid(y=audio_segment, sr=sr)[0]
    features['spectral_centroid'] = np.mean(spectral_centroid)
    
    # 3. è¿‡é›¶ç‡
    zcr = librosa.feature.zero_crossing_rate(audio_segment)[0]
    features['zcr'] = np.mean(zcr)
    
    # 4. MFCCç‰¹å¾
    mfccs = librosa.feature.mfcc(y=audio_segment, sr=sr, n_mfcc=13)
    features['mfcc_mean'] = np.mean(mfccs, axis=1)
    
    # 5. è‰²åº¦ç‰¹å¾
    chroma = librosa.feature.chroma_stft(y=audio_segment, sr=sr)
    features['chroma_mean'] = np.mean(chroma, axis=1)
    
    # 6. éŸ³ç¬¦èµ·å§‹å¼ºåº¦
    onset_strength = librosa.onset.onset_strength(y=audio_segment, sr=sr)
    features['onset_strength'] = np.mean(onset_strength)
    
    return features

def generate_training_label(start_time, end_time, note_times, note_columns):
    """ç”Ÿæˆè®­ç»ƒæ ‡ç­¾"""
    # æŸ¥æ‰¾è¿™ä¸ªæ—¶é—´çª—å£å†…çš„éŸ³ç¬¦
    mask = (note_times >= start_time) & (note_times < end_time)
    window_notes = note_times[mask]
    window_columns = note_columns[mask]
    
    if len(window_notes) > 0:
        return {
            'has_note': True,
            'note_count': len(window_notes),
            'columns': list(window_columns),
            'note_times': list(window_notes - start_time)  # ç›¸å¯¹æ—¶é—´
        }
    else:
        return {
            'has_note': False,
            'note_count': 0,
            'columns': [],
            'note_times': []
        }

def explain_ml_approach():
    """è§£é‡Šæœºå™¨å­¦ä¹ æ–¹æ³•"""
    print(f"\nğŸ¤– æœºå™¨å­¦ä¹ æ–¹æ³•è¯¦è§£:")
    print(f"=" * 40)
    
    print(f"ğŸ“š ç›‘ç£å­¦ä¹ æ–¹æ³•:")
    print(f"   â€¢ è¾“å…¥ X: éŸ³é¢‘ç‰¹å¾å‘é‡ (ç»´åº¦: ~50-100)")
    print(f"   â€¢ è¾“å‡º Y: éŸ³ç¬¦å­˜åœ¨æ¦‚ç‡ + é”®ä½åˆ†å¸ƒ")
    print(f"   â€¢ æ¨¡å‹: ç¥ç»ç½‘ç»œ / éšæœºæ£®æ— / XGBoost")
    print(f"   â€¢ è®­ç»ƒæ•°æ®: 354ä¸ªè°±é¢ Ã— çº¦2800ä¸ªæ ·æœ¬/è°±é¢")
    
    print(f"\nğŸ¯ å…·ä½“å®ç°:")
    print(f"   1. æ•°æ®å‡†å¤‡:")
    print(f"      â€¢ ä»MCZæ–‡ä»¶æå–éŸ³é¢‘å’Œè°±é¢")
    print(f"      â€¢ æ—¶é—´å¯¹é½: éŸ³é¢‘æ—¶é—´ â†” è°±é¢beat")
    print(f"      â€¢ çª—å£åŒ–: è¿ç»­éŸ³é¢‘ â†’ ç¦»æ•£æ ·æœ¬")
    
    print(f"\n   2. ç‰¹å¾å·¥ç¨‹:")
    print(f"      â€¢ æ—¶åŸŸç‰¹å¾: RMSèƒ½é‡, è¿‡é›¶ç‡")
    print(f"      â€¢ é¢‘åŸŸç‰¹å¾: é¢‘è°±è´¨å¿ƒ, MFCC, è‰²åº¦")
    print(f"      â€¢ èŠ‚æ‹ç‰¹å¾: éŸ³ç¬¦èµ·å§‹å¼ºåº¦, æœ¬åœ°tempo")
    print(f"      â€¢ ä¸Šä¸‹æ–‡ç‰¹å¾: å‰åçª—å£çš„ç‰¹å¾")
    
    print(f"\n   3. æ ‡ç­¾è®¾è®¡:")
    print(f"      â€¢ åˆ†ç±»é—®é¢˜: æœ‰éŸ³ç¬¦(1) vs æ— éŸ³ç¬¦(0)")
    print(f"      â€¢ å¤šæ ‡ç­¾é—®é¢˜: é”®ä½0, é”®ä½1, é”®ä½2, é”®ä½3")
    print(f"      â€¢ å›å½’é—®é¢˜: éŸ³ç¬¦å¯†åº¦, éš¾åº¦è¯„ä¼°")
    
    print(f"\n   4. æ¨¡å‹è®­ç»ƒ:")
    print(f"      â€¢ æŸå¤±å‡½æ•°: äº¤å‰ç†µ + é”®ä½åˆ†é…æŸå¤±")
    print(f"      â€¢ ä¼˜åŒ–: Adamä¼˜åŒ–å™¨, å­¦ä¹ ç‡è°ƒåº¦")
    print(f"      â€¢ æ­£åˆ™åŒ–: Dropout, æƒé‡è¡°å‡")
    print(f"      â€¢ éªŒè¯: äº¤å‰éªŒè¯, æµ‹è¯•é›†è¯„ä¼°")
    
    print(f"\nğŸ“Š æˆ‘ä»¬çš„è®­ç»ƒç»“æœ:")
    print(f"   â€¢ è®­ç»ƒæ ·æœ¬: 899,985ä¸ª")
    print(f"   â€¢ æœ€ç»ˆå‡†ç¡®ç‡: 74.6%")
    print(f"   â€¢ è¿™æ„å‘³ç€: çº¦3/4çš„æ—¶é—´ç‚¹é¢„æµ‹æ­£ç¡®")

def compare_with_simple_generation():
    """å¯¹æ¯”ç®€å•ç”Ÿæˆæ–¹æ³•å’Œæœºå™¨å­¦ä¹ æ–¹æ³•"""
    print(f"\nâš–ï¸  æ–¹æ³•å¯¹æ¯”:")
    print(f"=" * 40)
    
    print(f"ğŸ”§ ç®€å•è§„åˆ™æ–¹æ³• (å¦‚æˆ‘ä»¬åˆšæ‰ç”Ÿæˆçš„è°±é¢):")
    print(f"   âœ… ä¼˜ç‚¹:")
    print(f"      â€¢ å¿«é€Ÿç”Ÿæˆ, æ— éœ€è®­ç»ƒ")
    print(f"      â€¢ å¯æ§æ€§å¼º, å®¹æ˜“è°ƒå‚")
    print(f"      â€¢ ä¿è¯å®Œæ•´æ—¶é•¿è¦†ç›–")
    print(f"   âŒ ç¼ºç‚¹:")
    print(f"      â€¢ ç¼ºä¹éŸ³ä¹ç†è§£")
    print(f"      â€¢ éšæœºæ€§å¼º, ä¸å¤Ÿç²¾ç¡®")
    print(f"      â€¢ éš¾ä»¥é€‚åº”ä¸åŒé£æ ¼")
    
    print(f"\nğŸ§  æœºå™¨å­¦ä¹ æ–¹æ³•:")
    print(f"   âœ… ä¼˜ç‚¹:")
    print(f"      â€¢ å­¦ä¹ çœŸå®è°±é¢æ¨¡å¼")
    print(f"      â€¢ é€‚åº”éŸ³é¢‘ç‰¹å¾")
    print(f"      â€¢ å¯ä»¥ç”Ÿæˆä¸åŒé£æ ¼")
    print(f"   âŒ ç¼ºç‚¹:")
    print(f"      â€¢ éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®")
    print(f"      â€¢ è®­ç»ƒæ—¶é—´é•¿")
    print(f"      â€¢ å¯èƒ½è¿‡æ‹Ÿåˆç‰¹å®šé£æ ¼")
    
    print(f"\nğŸ¯ æœ€ä½³å®è·µç»„åˆ:")
    print(f"   â€¢ ç”¨MLå­¦ä¹ éŸ³ç¬¦æ”¾ç½®çš„æ—¶æœº")
    print(f"   â€¢ ç”¨è§„åˆ™æ§åˆ¶æ•´ä½“ç»“æ„å’Œéš¾åº¦")
    print(f"   â€¢ ç”¨éŸ³ä¹ç†è®ºæŒ‡å¯¼é”®ä½åˆ†é…")
    print(f"   â€¢ ç”¨åå¤„ç†ä¼˜åŒ–æ¸¸æˆä½“éªŒ")

if __name__ == "__main__":
    # æ¼”ç¤ºå®Œæ•´çš„ç‰¹å¾æå–æµç¨‹
    result = demonstrate_feature_extraction_pipeline()
    
    # è§£é‡Šæœºå™¨å­¦ä¹ æ–¹æ³•
    explain_ml_approach()
    
    # å¯¹æ¯”ä¸åŒæ–¹æ³•
    compare_with_simple_generation()
