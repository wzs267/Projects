#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ è®­ç»ƒè„šæœ¬
åˆ©ç”¨700+ä¸ªMCZæ–‡ä»¶è¿›è¡Œå®Œæ•´çš„æ·±åº¦å­¦ä¹ è®­ç»ƒ
"""

import os
import sys
import time
import gc
from scripts.deep_learning_beatmap_system import DeepBeatmapLearningSystem

def large_scale_training():
    """å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ è®­ç»ƒ"""
    print("ğŸ® å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ éŸ³æ¸¸è°±é¢ç”Ÿæˆè®­ç»ƒ")
    print("=" * 60)
    print("ğŸ“‚ å‡†å¤‡å¤„ç†700+ä¸ªMCZæ–‡ä»¶...")
    
    # åˆ›å»ºé«˜æ€§èƒ½ç³»ç»Ÿå®ä¾‹
    system = DeepBeatmapLearningSystem(
        sequence_length=64,    # è¾ƒé•¿çš„åºåˆ—ä»¥æ•è·éŸ³ä¹æ¨¡å¼
        batch_size=64,         # è¾ƒå¤§çš„æ‰¹æ¬¡ä»¥æé«˜è®­ç»ƒæ•ˆç‡
        learning_rate=0.0005   # è¾ƒå°çš„å­¦ä¹ ç‡ä»¥ç¨³å®šè®­ç»ƒ
    )
    
    start_time = time.time()
    
    try:
        # é˜¶æ®µ1: æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
        print("\nğŸ” é˜¶æ®µ1: åŠ è½½å¤§è§„æ¨¡æ•°æ®é›†...")
        print("âš ï¸  è¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        # æ£€æŸ¥trainDataç›®å½•
        traindata_dir = 'trainData'
        if not os.path.exists(traindata_dir):
            print(f"âŒ æ‰¾ä¸åˆ°è®­ç»ƒæ•°æ®ç›®å½•: {traindata_dir}")
            return
        
        mcz_files = [f for f in os.listdir(traindata_dir) if f.endswith('.mcz')]
        print(f"ğŸ“Š å‘ç° {len(mcz_files)} ä¸ªMCZæ–‡ä»¶")
        
        if len(mcz_files) == 0:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°MCZæ–‡ä»¶")
            return
        
        # åˆ†æ‰¹å¤„ç†ä»¥é¿å…å†…å­˜æº¢å‡º
        batch_size = 50  # æ¯æ¬¡å¤„ç†50ä¸ªMCZæ–‡ä»¶
        total_audio_features = []
        total_beatmap_labels = []
        
        for batch_start in range(0, min(200, len(mcz_files)), batch_size):  # å…ˆå¤„ç†200ä¸ªæ–‡ä»¶
            batch_end = min(batch_start + batch_size, len(mcz_files))
            batch_files = mcz_files[batch_start:batch_end]
            
            print(f"\nğŸ“¦ å¤„ç†æ‰¹æ¬¡ [{batch_start//batch_size + 1}]: æ–‡ä»¶ {batch_start+1}-{batch_end}")
            
            try:
                # ä¸´æ—¶å¤„ç†è¿™ä¸€æ‰¹æ–‡ä»¶
                temp_system = DeepBeatmapLearningSystem(sequence_length=32, batch_size=16)
                audio_features, beatmap_labels = temp_system.load_batch_dataset(
                    traindata_dir, batch_files
                )
                
                if audio_features is not None and beatmap_labels is not None:
                    total_audio_features.append(audio_features)
                    total_beatmap_labels.append(beatmap_labels)
                    print(f"âœ… æ‰¹æ¬¡å®Œæˆ: {audio_features.shape[0]:,} ä¸ªæ ·æœ¬")
                else:
                    print("âš ï¸  æ‰¹æ¬¡å¤„ç†å¤±è´¥")
                
                # æ¸…ç†å†…å­˜
                del temp_system, audio_features, beatmap_labels
                gc.collect()
                
            except Exception as e:
                print(f"âŒ æ‰¹æ¬¡å¤„ç†å‡ºé”™: {e}")
                continue
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        if not total_audio_features:
            print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ•°æ®")
            return
        
        print("\nğŸ”— åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡æ•°æ®...")
        import numpy as np
        final_audio_features = np.vstack(total_audio_features)
        final_beatmap_labels = np.vstack(total_beatmap_labels)
        
        print(f"ğŸ“Š æœ€ç»ˆæ•°æ®é›†å¤§å°: {final_audio_features.shape[0]:,} ä¸ªæ ·æœ¬")
        print(f"ğŸµ ç‰¹å¾ç»´åº¦: {final_audio_features.shape[1]}")
        print(f"ğŸ® æ ‡ç­¾ç»´åº¦: {final_beatmap_labels.shape[1]}")
        
        # æ¸…ç†ä¸´æ—¶æ•°æ®
        del total_audio_features, total_beatmap_labels
        gc.collect()
        
        # é˜¶æ®µ2: æ¨¡å‹åˆ›å»ºå’Œè®­ç»ƒå‡†å¤‡
        print("\nğŸ—ï¸  é˜¶æ®µ2: åˆ›å»ºæ·±åº¦å­¦ä¹ æ¨¡å‹...")
        system.create_model(input_dim=final_audio_features.shape[1])
        
        print("\nğŸ”§ é˜¶æ®µ3: å‡†å¤‡è®­ç»ƒæ•°æ®...")
        train_loader, val_loader = system.prepare_training_data(
            final_audio_features, final_beatmap_labels, train_ratio=0.85
        )
        
        # æ¸…ç†å¤§æ•°ç»„
        del final_audio_features, final_beatmap_labels
        gc.collect()
        
        # é˜¶æ®µ4: æ·±åº¦å­¦ä¹ è®­ç»ƒ
        print("\nğŸš€ é˜¶æ®µ4: å¼€å§‹å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ è®­ç»ƒ...")
        print("ğŸ“‹ è®­ç»ƒé…ç½®:")
        print(f"   â€¢ åºåˆ—é•¿åº¦: {system.sequence_length}")
        print(f"   â€¢ æ‰¹æ¬¡å¤§å°: {system.batch_size}")
        print(f"   â€¢ å­¦ä¹ ç‡: {system.learning_rate}")
        print(f"   â€¢ æ¨¡å‹å‚æ•°: {sum(p.numel() for p in system.model.parameters()):,}")
        print(f"   â€¢ è®­ç»ƒæ‰¹æ¬¡: {len(train_loader)}")
        print(f"   â€¢ éªŒè¯æ‰¹æ¬¡: {len(val_loader)}")
        
        # å¼€å§‹è®­ç»ƒ
        system.train(
            train_loader, val_loader,
            num_epochs=100,  # 100è½®è®­ç»ƒ
            save_path='large_scale_beatmap_model.pth'
        )
        
        # é˜¶æ®µ5: ç»“æœåˆ†æå’Œä¿å­˜
        print("\nğŸ“Š é˜¶æ®µ5: åˆ†æè®­ç»ƒç»“æœ...")
        system.plot_training_history()
        
        # ä¿å­˜è®­ç»ƒå†å²
        import json
        history_data = {
            'training_config': {
                'sequence_length': system.sequence_length,
                'batch_size': system.batch_size,
                'learning_rate': system.learning_rate,
                'model_parameters': sum(p.numel() for p in system.model.parameters()),
                'training_batches': len(train_loader),
                'validation_batches': len(val_loader)
            },
            'training_history': system.training_history,
            'final_performance': {
                'final_train_loss': system.training_history['train_loss'][-1],
                'final_val_loss': system.training_history['val_loss'][-1],
                'final_note_accuracy': system.training_history['note_accuracy'][-1],
                'final_event_accuracy': system.training_history['event_accuracy'][-1],
                'best_val_loss': min(system.training_history['val_loss'])
            }
        }
        
        with open('large_scale_training_results.json', 'w', encoding='utf-8') as f:
            json.dump(history_data, f, indent=2, ensure_ascii=False)
        
        # è®¡ç®—è®­ç»ƒæ—¶é—´
        total_time = time.time() - start_time
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = int(total_time % 60)
        
        print("\nğŸ‰ å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ è®­ç»ƒå®Œæˆï¼")
        print("=" * 60)
        print("ğŸ“ˆ æœ€ç»ˆç»“æœ:")
        print(f"   â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {hours:02d}:{minutes:02d}:{seconds:02d}")
        print(f"   ğŸ“Š æœ€ç»ˆéªŒè¯æŸå¤±: {system.training_history['val_loss'][-1]:.4f}")
        print(f"   ğŸ¯ æœ€ä½³éªŒè¯æŸå¤±: {min(system.training_history['val_loss']):.4f}")
        print(f"   ğŸµ éŸ³ç¬¦å‡†ç¡®ç‡: {system.training_history['note_accuracy'][-1]:.3f}")
        print(f"   ğŸ¼ äº‹ä»¶å‡†ç¡®ç‡: {system.training_history['event_accuracy'][-1]:.3f}")
        print("\nğŸ’¾ ä¿å­˜æ–‡ä»¶:")
        print("   â€¢ large_scale_beatmap_model.pth - æœ€ä½³æ¨¡å‹")
        print("   â€¢ large_scale_training_results.json - è®­ç»ƒå†å²")
        print("   â€¢ deep_learning_training_history.png - è®­ç»ƒå›¾è¡¨")
        
        return system
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None


def create_batch_loading_method():
    """ä¸ºDeepBeatmapLearningSystemæ·»åŠ æ‰¹é‡åŠ è½½æ–¹æ³•"""
    
    # å…ˆè¯»å–åŸæ–‡ä»¶å†…å®¹
    with open('deep_learning_beatmap_system.py', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ·»åŠ æ‰¹é‡åŠ è½½æ–¹æ³•
    batch_method = '''
    def load_batch_dataset(self, traindata_dir: str, mcz_files: List[str]) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """
        åˆ†æ‰¹åŠ è½½æ•°æ®é›†ä»¥é¿å…å†…å­˜æº¢å‡º
        
        Args:
            traindata_dir: è®­ç»ƒæ•°æ®ç›®å½•
            mcz_files: MCZæ–‡ä»¶åˆ—è¡¨
            
        Returns:
            (audio_features, beatmap_labels): éŸ³é¢‘ç‰¹å¾å’Œè°±é¢æ ‡ç­¾
        """
        print(f"ğŸ”„ æ‰¹é‡å¤„ç† {len(mcz_files)} ä¸ªMCZæ–‡ä»¶...")
        
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        try:
            from core.mcz_parser import MCZParser
            from core.four_k_extractor import FourKBeatmapExtractor
            from core.audio_beatmap_analyzer import AudioBeatmapAnalyzer
        except ImportError as e:
            print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            return None, None
        
        parser = MCZParser()
        extractor = FourKBeatmapExtractor()
        analyzer = AudioBeatmapAnalyzer(time_resolution=0.05)
        
        all_audio_features = []
        all_beatmap_labels = []
        processed_count = 0
        
        for i, mcz_file in enumerate(mcz_files):
            try:
                mcz_path = os.path.join(traindata_dir, mcz_file)
                if not os.path.exists(mcz_path):
                    continue
                
                print(f"   ğŸ“ [{i+1}/{len(mcz_files)}]: {mcz_file[:50]}...")
                
                # è§£æMCZæ–‡ä»¶
                song_data = parser.parse_mcz_file(mcz_path)
                if not song_data:
                    continue
                
                # æå–4Kè°±é¢
                beatmaps_4k = extractor.extract_4k_beatmaps(song_data)
                if not beatmaps_4k:
                    continue
                
                # æå–éŸ³é¢‘æ–‡ä»¶
                temp_audio_dir = f"temp_audio_{i}"
                os.makedirs(temp_audio_dir, exist_ok=True)
                
                try:
                    extracted_audio = parser.extract_audio_files(mcz_path, temp_audio_dir)
                    if not extracted_audio:
                        continue
                    
                    # å¤„ç†ç¬¬ä¸€ä¸ª4Kè°±é¢å’Œç¬¬ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶
                    beatmap = beatmaps_4k[0]
                    audio_file = extracted_audio[0]
                    
                    # åˆ†æéŸ³é¢‘å’Œè°±é¢
                    aligned_data = analyzer.align_audio_and_beatmap(
                        audio_file, beatmap, {}
                    )
                    
                    if aligned_data and len(aligned_data.audio_features) > self.sequence_length:
                        all_audio_features.append(aligned_data.audio_features)
                        all_beatmap_labels.append(aligned_data.beatmap_events)
                        processed_count += 1
                        
                        # é™åˆ¶æ¯æ‰¹æ¬¡çš„æ ·æœ¬æ•°é‡
                        if processed_count >= 20:  # æ¯æ‰¹æ¬¡æœ€å¤š20ä¸ªè°±é¢
                            break
                
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    import shutil
                    if os.path.exists(temp_audio_dir):
                        shutil.rmtree(temp_audio_dir)
                        
            except Exception as e:
                print(f"     âš ï¸ å¤„ç†å¤±è´¥: {e}")
                continue
        
        if processed_count == 0:
            print("âŒ è¯¥æ‰¹æ¬¡æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ•°æ®")
            return None, None
        
        # åˆå¹¶æ•°æ®
        try:
            audio_features = np.vstack(all_audio_features)
            beatmap_labels = np.vstack(all_beatmap_labels)
            print(f"âœ… æ‰¹æ¬¡å®Œæˆ: {processed_count} ä¸ªè°±é¢, {audio_features.shape[0]:,} ä¸ªæ ·æœ¬")
            return audio_features, beatmap_labels
        except Exception as e:
            print(f"âŒ æ•°æ®åˆå¹¶å¤±è´¥: {e}")
            return None, None
'''
    
    # æ‰¾åˆ°ç±»å®šä¹‰çš„ç»“æŸä½ç½®å¹¶æ’å…¥æ–°æ–¹æ³•
    class_end_pos = content.rfind('def plot_training_history(self):')
    if class_end_pos != -1:
        insert_pos = content.rfind('\n', 0, class_end_pos)
        new_content = content[:insert_pos] + batch_method + content[insert_pos:]
        
        # å†™å›æ–‡ä»¶
        with open('deep_learning_beatmap_system.py', 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print("âœ… å·²æ·»åŠ æ‰¹é‡åŠ è½½æ–¹æ³•åˆ°æ·±åº¦å­¦ä¹ ç³»ç»Ÿ")
    else:
        print("âŒ æ— æ³•æ‰¾åˆ°æ’å…¥ä½ç½®")


if __name__ == "__main__":
    print("ğŸ”§ å‡†å¤‡å¤§è§„æ¨¡è®­ç»ƒç¯å¢ƒ...")
    
    # æ·»åŠ æ‰¹é‡åŠ è½½æ–¹æ³•
    create_batch_loading_method()
    
    # å¼€å§‹å¤§è§„æ¨¡è®­ç»ƒ
    trained_system = large_scale_training()
    
    if trained_system:
        print("\nğŸŠ å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ è®­ç»ƒæˆåŠŸå®Œæˆï¼")
        print("ğŸš€ ç³»ç»Ÿç°åœ¨å¯ä»¥åŸºäº700+è°±é¢çš„å­¦ä¹ ç»“æœç”Ÿæˆé«˜è´¨é‡è°±é¢ï¼")
    else:
        print("\nğŸ’¥ è®­ç»ƒè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ä¿¡æ¯")
