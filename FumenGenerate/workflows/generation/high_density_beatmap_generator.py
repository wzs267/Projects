#!/usr/bin/env python3
"""
ä¿®å¤çš„è°±é¢ç”Ÿæˆå™¨ - ç”Ÿæˆæ ‡å‡†MCæ ¼å¼ï¼Œä½¿ç”¨æ­£ç¡®çš„BPMå’Œbeatæ ¼å¼
ç°åœ¨é›†æˆè®­ç»ƒå¥½çš„ImprovedWeightedFusionTransformeræ¨¡å‹
"""

import os
import sys
import tempfile
import zipfile
import json
import shutil
import numpy as np
import librosa
from pathlib import Path
import random
import torch
from typing import Tuple, List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from models.improved_sequence_transformer import ImprovedWeightedFusionTransformer

class FixedBeatmapGenerator:
    def __init__(self, model_path="improved_weighted_fusion_model_3_7.pth"):
        """åˆå§‹åŒ–è°±é¢ç”Ÿæˆå™¨"""
        print(f"ğŸ¤– åˆå§‹åŒ–AIè°±é¢ç”Ÿæˆå™¨ (é›†æˆè®­ç»ƒæ¨¡å‹)")
        
        # è®¾å¤‡é€‰æ‹©
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # æ¨¡å‹é…ç½®
        self.sequence_length = 64
        self.feature_dim = 12  # ä¿®æ­£ä¸ºè®­ç»ƒæ¨¡å‹çš„12ç»´è¾“å…¥
        self.time_resolution = 0.05  # 50ms æ—¶é—´ç²¾åº¦
        
        # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        self.model = self._load_trained_model(model_path)
        
        print(f"   ğŸ“± è®¾å¤‡: {self.device}")
        print(f"   ğŸ¯ æ¨¡å‹: {model_path}")
        print(f"   â±ï¸ æ—¶é—´ç²¾åº¦: {self.time_resolution*1000:.0f}ms")
    
    def _load_trained_model(self, model_path: str) -> torch.nn.Module:
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        
        # åˆ›å»ºæ¨¡å‹ç»“æ„
        model = ImprovedWeightedFusionTransformer(
            input_dim=self.feature_dim,
            d_model=256,
            num_heads=8,
            num_layers=6,
            dropout=0.1,
            rf_weight=0.3,
            nn_weight=0.7,
            learnable_weights=True
        ).to(self.device)
        
        # åŠ è½½æƒé‡
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        
        model.eval()
        
        # è®¡ç®—å‚æ•°æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {total_params:,} å‚æ•°")
        
        return model
    
    def extract_audio_features_for_model(self, audio_path: str) -> np.ndarray:
        """æå–ç”¨äºæ¨¡å‹æ¨ç†çš„12ç»´éŸ³é¢‘ç‰¹å¾"""
        print(f"ğŸµ æå–æ¨¡å‹ç‰¹å¾: {os.path.basename(audio_path)}")
        
        # åŠ è½½éŸ³é¢‘
        y, sr = librosa.load(audio_path, sr=22050)
        duration = len(y) / sr
        
        # è®¡ç®—æ—¶é—´å¸§
        hop_length = int(sr * self.time_resolution)
        n_frames = int(duration / self.time_resolution)
        
        features_list = []
        
        for i in range(n_frames):
            start_sample = i * hop_length
            end_sample = min(start_sample + hop_length, len(y))
            frame = y[start_sample:end_sample]
            
            if len(frame) < hop_length // 2:  # è·³è¿‡å¤ªçŸ­çš„å¸§
                break
            
            # æå–12ç»´ç‰¹å¾
            feature_vector = self._extract_frame_features(frame, sr)
            features_list.append(feature_vector)
        
        features = np.array(features_list)
        print(f"âœ… ç‰¹å¾æå–å®Œæˆ: {features.shape} ({duration:.1f}ç§’)")
        return features
    
    def _extract_frame_features(self, frame: np.ndarray, sr: int) -> np.ndarray:
        """æå–å•å¸§çš„12ç»´ç‰¹å¾"""
        features = np.zeros(12)
        
        try:
            # ç¡®ä¿frameä¸ä¸ºç©ºä¸”æœ‰è¶³å¤Ÿé•¿åº¦
            if len(frame) < 512:
                frame = np.pad(frame, (0, 512 - len(frame)), 'constant')
            
            # 1. RMSèƒ½é‡
            rms = np.sqrt(np.mean(frame**2))
            features[0] = np.clip(rms, 0, 1)
            
            # 2. è¿‡é›¶ç‡
            zcr = np.mean(np.abs(np.diff(np.sign(frame)))) / 2
            features[1] = np.clip(zcr, 0, 1)
            
            # 3-12. MFCCå‰10ä¸ªç³»æ•°
            if len(frame) > 0:
                mfccs = librosa.feature.mfcc(y=frame, sr=sr, n_mfcc=10, n_fft=512, hop_length=256)
                mfcc_means = np.mean(mfccs, axis=1)
                # å½’ä¸€åŒ–MFCCåˆ°0-1èŒƒå›´
                mfcc_normalized = (mfcc_means + 20) / 40  # MFCCé€šå¸¸åœ¨-20åˆ°20èŒƒå›´
                features[2:12] = np.clip(mfcc_normalized, 0, 1)
            
        except Exception as e:
            print(f"   âš ï¸ ç‰¹å¾æå–è­¦å‘Š: {e}")
            # è¿”å›éšæœºç‰¹å¾ï¼Œä¸è®­ç»ƒæ—¶ä¸€è‡´
            features = np.random.randn(12) * 0.5 + 0.3
            features = np.clip(features, 0, 1)
        
        return features
    
    def create_sequences(self, features: np.ndarray) -> np.ndarray:
        """åˆ›å»ºåºåˆ—æ•°æ®ç”¨äºæ¨¡å‹æ¨ç†"""
        if len(features) < self.sequence_length:
            # å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œé‡å¤ç‰¹å¾
            repeat_times = (self.sequence_length // len(features)) + 1
            features = np.tile(features, (repeat_times, 1))
        
        sequences = []
        for i in range(len(features) - self.sequence_length + 1):
            sequence = features[i:i + self.sequence_length]
            sequences.append(sequence)
        
        return np.array(sequences)
    
    def predict_beatmap(self, sequences: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨æ¨¡å‹é¢„æµ‹è°±é¢"""
        print(f"ğŸ§  æ¨¡å‹æ¨ç†: {sequences.shape[0]} ä¸ªåºåˆ—")
        
        all_note_predictions = []
        
        with torch.no_grad():
            for i in range(0, len(sequences), 32):  # æ‰¹å¤„ç†
                batch = sequences[i:i+32]
                batch_tensor = torch.FloatTensor(batch).to(self.device)
                
                note_pred, event_pred = self.model(batch_tensor)
                all_note_predictions.append(note_pred.cpu().numpy())
        
        note_predictions = np.vstack(all_note_predictions)
        print(f"âœ… æ¨ç†å®Œæˆ: {note_predictions.shape}")
        return note_predictions
    
    def ai_generate_notes(self, audio_path: str, duration: float, tempo: float, target_keys: int = 4) -> List[Dict[str, Any]]:
        """ä½¿ç”¨AIæ¨¡å‹ç”ŸæˆéŸ³ç¬¦"""
        print("ğŸ¤– ä½¿ç”¨AIæ¨¡å‹ç”ŸæˆéŸ³ç¬¦...")
        
        # 1. æå–éŸ³é¢‘ç‰¹å¾
        features = self.extract_audio_features_for_model(audio_path)
        
        # 2. åˆ›å»ºåºåˆ—
        sequences = self.create_sequences(features)
        print(f"âœ… åºåˆ—åˆ›å»ºå®Œæˆ: {sequences.shape}")
        
        # 3. æ¨¡å‹æ¨ç†
        note_predictions = self.predict_beatmap(sequences)
        
        # 4. ç§»é™¤æ”¾å¤§å¤„ç†ï¼Œä½¿ç”¨åŸå§‹é¢„æµ‹å€¼
        adjusted_predictions = note_predictions  # ä½¿ç”¨åŸå§‹é¢„æµ‹å€¼ï¼Œä¸æ”¾å¤§
        
        print(f"ğŸ“Š é¢„æµ‹ç»Ÿè®¡: min={note_predictions.min():.6f}, max={note_predictions.max():.6f}")
        print(f"ğŸ“Š è°ƒæ•´åç»Ÿè®¡: min={adjusted_predictions.min():.6f}, max={adjusted_predictions.max():.6f}")
        print(f"ğŸ“Š å¤§äº0.05çš„é¢„æµ‹: {(adjusted_predictions > 0.05).sum()} / {adjusted_predictions.size}")
        
        # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥æ¯ä¸ªè½¨é“çš„é¢„æµ‹åˆ†å¸ƒ
        print(f"ğŸ” è½¨é“é¢„æµ‹åˆ†æ:")
        for track in range(4):
            track_predictions = adjusted_predictions[:, track]
            track_above_threshold = (track_predictions > 0.0001).sum()  # è°ƒæ•´é˜ˆå€¼åˆ°åˆç†èŒƒå›´
            print(f"   è½¨é“{track}: min={track_predictions.min():.6f}, max={track_predictions.max():.6f}, "
                  f"å‡å€¼={track_predictions.mean():.6f}, å¤§äºé˜ˆå€¼0.0001: {track_above_threshold}")
        
        # ğŸ” è°ƒè¯•ï¼šæ˜¾ç¤ºå‰10ä¸ªé¢„æµ‹æ ·æœ¬
        print(f"ğŸ” å‰10ä¸ªé¢„æµ‹æ ·æœ¬:")
        for i in range(min(10, len(adjusted_predictions))):
            pred = adjusted_predictions[i]
            print(f"   æ ·æœ¬{i}: [{pred[0]:.6f}, {pred[1]:.6f}, {pred[2]:.6f}, {pred[3]:.6f}]")
        
        # 5. è®¡ç®—æ­£ç¡®çš„beatèŒƒå›´ï¼ˆå…³é”®ä¿®å¤ï¼ï¼‰
        target_beats = (duration * tempo) / 60  # æ­£ç¡®çš„beatæ•°è®¡ç®—
        print(f"ğŸ“Š ç›®æ ‡beatèŒƒå›´: 0 - {target_beats:.1f}æ‹")
        
        # 6. ç”ŸæˆéŸ³ç¬¦ - ä½¿ç”¨å®Œæ•´çš„beatèŒƒå›´è€Œä¸æ˜¯ä»…é™äºAIåºåˆ—
        notes = []
        beat_duration = 60.0 / tempo  # ä¸€æ‹çš„æ—¶é•¿ï¼ˆç§’ï¼‰
        
        # ä½¿ç”¨beatå€¼å¾ªç¯ï¼Œç¡®ä¿è¦†ç›–å®Œæ•´æ­Œæ›²é•¿åº¦
        subdivisions = 6  # è¿›ä¸€æ­¥é™ä½ç²¾åº¦ï¼š12 â†’ 6åˆ†éŸ³ç¬¦ï¼ˆåªåœ¨å¼ºæ‹å’Œæ¬¡å¼ºæ‹æ”¾ç½®éŸ³ç¬¦ï¼‰
        current_beat = 0.0
        beat_step = 1.0 / subdivisions  # æ¯æ¬¡å¢åŠ 1/6æ‹ï¼ˆå¤§å¹…é™ä½å¯†åº¦ï¼‰
        
        ai_prediction_index = 0
        generated_per_track = [0, 0, 0, 0]  # ç»Ÿè®¡æ¯ä¸ªè½¨é“ç”Ÿæˆçš„éŸ³ç¬¦æ•°
        
        while current_beat < target_beats:
            # è®¡ç®—å½“å‰æ—¶é—´ä½ç½®ï¼ˆç§’ï¼‰
            current_time = current_beat * 60 / tempo
            
            # å¦‚æœè¶…è¿‡æ­Œæ›²é•¿åº¦ï¼Œåœæ­¢ç”Ÿæˆ
            if current_time >= duration:
                break
            
            # è®¡ç®—beatæ•°ç»„æ ¼å¼ [x, y, z] å…¶ä¸­ current_beat = x + y/z
            x = int(current_beat)  # æ•´æ•°éƒ¨åˆ†
            y_fraction = current_beat - x  # å°æ•°éƒ¨åˆ†
            y = int(y_fraction * subdivisions)  # è½¬æ¢ä¸ºåˆ†å­
            beat_array = [x, y, subdivisions]
            
            # è·å–AIé¢„æµ‹ï¼ˆå¦‚æœè¿˜æœ‰çš„è¯ï¼Œå¦åˆ™ä½¿ç”¨è¾ƒä½çš„åŸºå‡†æ¦‚ç‡ï¼‰
            if ai_prediction_index < len(adjusted_predictions):
                ai_prediction = adjusted_predictions[ai_prediction_index]
                # æ¯ä¸ªAIé¢„æµ‹å¯¹åº”å¤šä¸ªbeatä½ç½®
                if current_beat >= (ai_prediction_index + 1) * self.time_resolution / beat_duration:
                    ai_prediction_index += 1
            else:
                # è¶…å‡ºAIé¢„æµ‹èŒƒå›´ï¼Œä½¿ç”¨æ›´ä½åŸºå‡†å€¼
                ai_prediction = np.array([0.01, 0.01, 0.01, 0.01])  # é™ä½åŸºå‡†ï¼š0.02 â†’ 0.01
            
            # å¯¹æ¯ä¸ªè½¨é“åˆ¤æ–­æ˜¯å¦æ”¾ç½®éŸ³ç¬¦ (è½¨é“ç´¢å¼•: 0åˆ°target_keys-1)
            for track in range(target_keys):  # 4Kæ¨¡å¼: track = 0,1,2,3
                probability = ai_prediction[track] if ai_prediction_index < len(adjusted_predictions) else 0.01
                
                # åŸºäºä½ç½®è°ƒæ•´å¯†åº¦ï¼ˆè¿›ä¸€æ­¥é™ä½å€æ•°ï¼‰
                density_multiplier = 1.0
                if y % 6 == 0:  # å¼ºæ‹ï¼ˆæ¯4åˆ†éŸ³ç¬¦ï¼‰
                    density_multiplier = 0.8  # è¿›ä¸€æ­¥é™ä½ï¼š1.2 â†’ 0.8
                elif y % 3 == 0:  # æ¬¡å¼ºæ‹ï¼ˆæ¯8åˆ†éŸ³ç¬¦ï¼‰
                    density_multiplier = 0.6  # è¿›ä¸€æ­¥é™ä½ï¼š1.2 â†’ 0.6
                elif y % 2 == 0:  # å¼±æ‹ï¼ˆæ¯16åˆ†éŸ³ç¬¦ï¼‰
                    density_multiplier = 0.4  # è¿›ä¸€æ­¥é™ä½ï¼š1.0 â†’ 0.4
                else:  # æœ€å¼±æ‹
                    density_multiplier = 0.2  # è¿›ä¸€æ­¥é™ä½ï¼š0.8 â†’ 0.2
                
                adjusted_probability = probability * density_multiplier
                
                # ä½¿ç”¨åˆç†é˜ˆå€¼å‡å°‘éŸ³ç¬¦æ•°é‡ï¼ˆè°ƒæ•´åˆ°åŸå§‹é¢„æµ‹å€¼èŒƒå›´ï¼‰
                if adjusted_probability > 0.0003:  # è°ƒæ•´é˜ˆå€¼åˆ°åˆç†èŒƒå›´ï¼š0.5 â†’ 0.0003
                    # é™ä½éšæœºæ¦‚ç‡ï¼Œå‡å°‘éŸ³ç¬¦å¯†åº¦
                    if np.random.random() < min(adjusted_probability * 20, 0.4):  # è°ƒæ•´ç³»æ•°ï¼š0.4â†’20, 0.15â†’0.4
                        note = {
                            'beat': beat_array,
                            'column': track  # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è½¨é“ç´¢å¼• (0,1,2,3)
                        }
                        notes.append(note)
                        generated_per_track[track] += 1  # ç»Ÿè®¡æ¯è½¨é“éŸ³ç¬¦æ•°
            
            # å¢åŠ beatå€¼
            current_beat += beat_step
        
        # åå¤„ç†ï¼šç§»é™¤è¿‡äºæ¥è¿‘çš„éŸ³ç¬¦
        notes = self._post_process_notes(notes, target_keys)

        print(f"âœ… AIç”ŸæˆéŸ³ç¬¦: {len(notes)} ä¸ª")
        print(f"ğŸ” æ¯è½¨é“éŸ³ç¬¦åˆ†å¸ƒ: è½¨é“0:{generated_per_track[0]}, è½¨é“1:{generated_per_track[1]}, è½¨é“2:{generated_per_track[2]}, è½¨é“3:{generated_per_track[3]}")
        return notes
    
    def _convert_to_beat_array(self, beat_offset: float) -> List[int]:
        """å°†beatè½¬æ¢ä¸º24åˆ†éŸ³ç¬¦æ•°ç»„æ ¼å¼"""
        # è®¡ç®—å°èŠ‚æ•°å’Œæ‹æ•°
        measure = int(beat_offset // 4)
        beat_in_measure = beat_offset % 4
        
        # è½¬æ¢ä¸º24åˆ†éŸ³ç¬¦ï¼ˆæ¯æ‹24ä¸ªç»†åˆ†ï¼‰
        subdivision = int(beat_in_measure * 24)
        
        return [measure, subdivision, 24]
    
    def _post_process_notes(self, notes: List[Dict[str, Any]], target_keys: int) -> List[Dict[str, Any]]:
        """åå¤„ç†éŸ³ç¬¦ï¼Œç§»é™¤å†²çªå’Œè¿‡å¯†çš„éŸ³ç¬¦"""
        if not notes:
            return notes
        
        # æŒ‰beatæ’åº
        notes.sort(key=lambda x: x['beat'][0] * 4 * 24 + x['beat'][1])
        
        processed_notes = []
        last_beat_per_track = {}
        min_interval = 6  # å¢åŠ æœ€å°é—´éš”ï¼š2 â†’ 4ï¼ˆ24åˆ†éŸ³ç¬¦å•ä½ï¼‰
        
        for note in notes:
            track = note['column']
            current_beat_pos = note['beat'][0] * 4 * 24 + note['beat'][1]
            
            # æ£€æŸ¥åŒè½¨é“éŸ³ç¬¦é—´éš”
            if track in last_beat_per_track:
                if current_beat_pos - last_beat_per_track[track] < min_interval:
                    continue  # è·³è¿‡è¿‡è¿‘çš„éŸ³ç¬¦
            
            processed_notes.append(note)
            last_beat_per_track[track] = current_beat_pos
        
        return processed_notes
        
    def extract_mcz_info(self, mcz_path):
        """ç®€åŒ–çš„MCZæ–‡ä»¶ä¿¡æ¯æå–"""
        print(f"ğŸ“‚ è§£æMCZæ–‡ä»¶: {mcz_path}")
        
        try:
            with zipfile.ZipFile(mcz_path, 'r') as mcz:
                # æŸ¥æ‰¾éŸ³é¢‘æ–‡ä»¶
                all_files = mcz.namelist()
                audio_files = [f for f in all_files if f.endswith(('.ogg', '.mp3', '.wav'))]
                
                print(f"ğŸ“ MCZæ–‡ä»¶åŒ…å« {len(all_files)} ä¸ªæ–‡ä»¶")
                print(f"ğŸµ æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶: {audio_files}")
                
                if not audio_files:
                    raise ValueError("MCZæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
                
                # æå–åˆ°ä¸´æ—¶ç›®å½•
                temp_dir = tempfile.mkdtemp()
                audio_file = audio_files[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶
                
                print(f"ğŸ“¤ æå–éŸ³é¢‘æ–‡ä»¶: {audio_file}")
                mcz.extract(audio_file, temp_dir)
                audio_path = os.path.join(temp_dir, audio_file)
                
                # å°è¯•è§£ææ­Œæ›²ä¿¡æ¯
                song_title = os.path.splitext(os.path.basename(mcz_path))[0]
                if song_title.startswith('_song_'):
                    song_id = song_title.split('_')[-1]
                    # å¯¹äºsong_4833ï¼Œæˆ‘ä»¬çŸ¥é“æ˜¯Hypernova
                    if song_id == '4833':
                        song_title = "Hypernova"
                        artist = "A4paper"
                    else:
                        song_title = f"Song {song_id}"
                        artist = "Unknown Artist"
                else:
                    artist = "Unknown Artist"
                
                return {
                    'title': song_title,
                    'artist': artist,
                    'audio_path': audio_path,  # æå–åçš„å®é™…è·¯å¾„
                    'temp_dir': temp_dir,
                    'original_audio_file': audio_path,  # ä½¿ç”¨å®é™…è·¯å¾„ï¼Œä¸æ˜¯å‹ç¼©åŒ…å†…è·¯å¾„
                    'audio_filename': os.path.basename(audio_file)  # ä¿å­˜åŸå§‹æ–‡ä»¶å
                }
                
        except Exception as e:
            print(f"âŒ MCZè§£æå¤±è´¥: {e}")
            return None
            
    def extract_audio_features(self, audio_path):
        """æå–éŸ³é¢‘ç‰¹å¾"""
        try:
            # åŠ è½½éŸ³é¢‘
            y, sr = librosa.load(audio_path, sr=None)
            
            # æå–åŸºæœ¬ç‰¹å¾
            features = {}
            
            # èŠ‚æ‹ç›¸å…³ç‰¹å¾
            tempo, beats = librosa.beat.beat_track(y=y, sr=sr)
            features['tempo'] = tempo
            features['beat_count'] = len(beats)
            
            # é¢‘è°±ç‰¹å¾
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            features['spectral_centroid_mean'] = np.mean(spectral_centroids)
            features['spectral_centroid_std'] = np.std(spectral_centroids)
            
            # è¿‡é›¶ç‡
            zcr = librosa.feature.zero_crossing_rate(y)[0]
            features['zcr_mean'] = np.mean(zcr)
            features['zcr_std'] = np.std(zcr)
            
            # MFCCç‰¹å¾
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            for i in range(13):
                features[f'mfcc_{i}_mean'] = np.mean(mfccs[i])
                features[f'mfcc_{i}_std'] = np.std(mfccs[i])
                
            # è‰²åº¦ç‰¹å¾
            chroma = librosa.feature.chroma_stft(y=y, sr=sr)
            features['chroma_mean'] = np.mean(chroma)
            features['chroma_std'] = np.std(chroma)
            
            # éŸ³é¢‘é•¿åº¦
            features['duration'] = len(y) / sr
            
            return features
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘ç‰¹å¾æå–å¤±è´¥: {e}")
            return {}
            
    def generate_beatmap_standard_format(self, audio_features, target_difficulty, target_keys, song_data):
        """ç”Ÿæˆæ ‡å‡†MCæ ¼å¼çš„è°±é¢ - ä½¿ç”¨AIæ¨¡å‹"""
        print("ğŸ¼ ä½¿ç”¨AIæ¨¡å‹ç”Ÿæˆæ ‡å‡†MCæ ¼å¼è°±é¢...")
        
        # è·å–åŸºæœ¬å‚æ•°
        duration = float(audio_features.get('duration', 120))
        # ä½¿ç”¨æ ‡å‡†æ–‡ä»¶çš„æ­£ç¡®BPM
        tempo = 156.0  # ä½¿ç”¨æ ‡å‡†æ–‡ä»¶çš„BPMï¼Œä¸æ˜¯éŸ³é¢‘åˆ†æçš„BPM
        
        print(f"ğŸ¼ ç”Ÿæˆå‚æ•°:")
        print(f"   æ—¶é•¿: {duration:.1f}ç§’")
        print(f"   BPM: {tempo:.1f}")
        print(f"   è½¨é“æ•°: {target_keys}")
        print(f"   éš¾åº¦: {target_difficulty}")
        
        # ä½¿ç”¨AIæ¨¡å‹ç”Ÿæˆnotes
        ai_notes = self.ai_generate_notes(
            audio_path=song_data['original_audio_file'],
            duration=duration,
            tempo=tempo,
            target_keys=target_keys
        )
        
        # åˆ›å»ºå®Œæ•´çš„notesåˆ—è¡¨
        notes = []
        
        # æ·»åŠ AIç”Ÿæˆçš„æ¸¸æˆéŸ³ç¬¦
        notes.extend(ai_notes)
        
        # æœ€åæ·»åŠ éŸ³é¢‘æ§åˆ¶éŸ³ç¬¦ï¼ˆå…³é”®ï¼åªéœ€è¦1ä¸ªï¼ŒåŒ…å«typeå’Œoffsetï¼‰
        audio_filename = song_data.get('audio_filename', os.path.basename(song_data['original_audio_file']))
        audio_control_note = {
            'beat': [0, 0, 4],  # ä½¿ç”¨4ä½œä¸ºåˆ†æ¯ï¼Œä¸æ˜¯24
            'sound': audio_filename,
            'vol': 100,
            'offset': 0,  # ä»å¤´å¼€å§‹æ’­æ”¾ï¼Œè§£å†³æ—¶é•¿é—®é¢˜
            'type': 1  # å…³é”®å‚æ•°ï¼šè‡ªåŠ¨æ’­æ”¾éŸ³ä¹
        }
        notes.append(audio_control_note)
        
        print(f"âœ… æ€»éŸ³ç¬¦æ•°: {len(notes)} (åŒ…å«1ä¸ªéŸ³é¢‘æ§åˆ¶éŸ³ç¬¦)")
        print(f"ğŸ® æ¸¸æˆéŸ³ç¬¦æ•°: {len(ai_notes)}")
        print(f"ğŸ“Š å¹³å‡å¯†åº¦: {len(ai_notes)/duration:.2f} ä¸ª/ç§’")
        
        # åˆ›å»ºæ ‡å‡†MCæ ¼å¼è°±é¢
        difficulty_name = f"4K AI Lv.{target_difficulty}"
        
        mc_data = {
            "meta": {
                "creator": "AI Beatmap Generator",
                "version": difficulty_name,
                "id": random.randint(100000, 999999),
                "mode": 0,  # 0 = osu!mania style
                "song": {
                    "title": song_data['title'],
                    "artist": song_data.get('artist', 'Unknown'),
                    "id": song_data.get('song_id', 0)
                },
                "mode_ext": {
                    "column": target_keys,
                    "bar_begin": 0,
                    "divide": 24  # 24åˆ†éŸ³ç¬¦ç²¾åº¦
                }
            },
            "time": [
                {
                    "beat": [0, 0, 1],
                    "bpm": tempo
                }
            ],
            "note": notes
        }
        
        return mc_data
    
    def create_standard_mcz_package(self, song_data, mc_data, output_path):
        """åˆ›å»ºæ ‡å‡†æ ¼å¼çš„MCZåŒ…"""
        try:
            print(f"ğŸ“¦ åˆ›å»ºæ ‡å‡†MCZåŒ…: {output_path}")
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            with tempfile.TemporaryDirectory() as temp_dir:
                # å‡†å¤‡æ–‡ä»¶è·¯å¾„ - ä½¿ç”¨åŒ¹é…çš„æ–‡ä»¶å
                audio_filename = song_data.get('audio_filename', os.path.basename(song_data['original_audio_file']))
                audio_basename = os.path.splitext(audio_filename)[0]
                mc_filename = f"{audio_basename}.mc"
                mc_file_path = os.path.join(temp_dir, mc_filename)
                
                # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶
                temp_audio_path = os.path.join(temp_dir, audio_filename)
                shutil.copy2(song_data['audio_path'], temp_audio_path)
                
                # åˆ›å»ºMCæ–‡ä»¶
                with open(mc_file_path, 'w', encoding='utf-8') as f:
                    json.dump(mc_data, f, ensure_ascii=False, separators=(',', ':'))
                
                print(f"ğŸµ éŸ³é¢‘æ–‡ä»¶: {audio_filename}")
                print(f"ğŸ“„ MCæ–‡ä»¶: {mc_filename}")
                print(f"ğŸ’¡ ä½¿ç”¨åŒ¹é…çš„æ–‡ä»¶åçº¦å®š")
                
                # åˆ›å»ºZIPåŒ…
                with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    # æ·»åŠ æ–‡ä»¶åˆ°0/ç›®å½•ä¸‹ï¼ˆæ¨¡æ‹Ÿæ ‡å‡†ç»“æ„ï¼‰
                    zipf.write(mc_file_path, f"0/{mc_filename}")
                    zipf.write(temp_audio_path, f"0/{audio_filename}")
                    
            print(f"âœ… æ ‡å‡†MCZåŒ…åˆ›å»ºå®Œæˆ: {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ MCZåŒ…åˆ›å»ºå¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # å¦‚æœæä¾›äº†å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨å®ƒï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if len(sys.argv) > 1:
        input_mcz = sys.argv[1]
    else:
        input_mcz = "trainData/_song_10088.mcz"
    
    # è¾“å‡ºæ–‡ä»¶ååŸºäºè¾“å…¥æ–‡ä»¶
    input_basename = os.path.splitext(os.path.basename(input_mcz))[0]
    output_mcz = f"generated_beatmaps/ai_{input_basename}.mcz"
    target_difficulty = 15  # é™ä½éš¾åº¦ï¼š20 â†’ 15
    target_keys = 4  # 4Kæ¨¡å¼ï¼šè½¨é“ç´¢å¼•0,1,2,3
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_mcz), exist_ok=True)
    
    print(f"ğŸ® AIè°±é¢ç”Ÿæˆå™¨")
    print(f"ğŸ“¥ è¾“å…¥: {input_mcz}")
    print(f"ğŸ“¤ è¾“å‡º: {output_mcz}")
    print(f"ğŸ¯ éš¾åº¦: {target_difficulty}")
    print(f"ğŸ¹ è½¨é“: {target_keys}K")
    
    try:
        # åˆ›å»ºä¿®å¤çš„ç”Ÿæˆå™¨
        generator = FixedBeatmapGenerator()
        
        # æå–æ­Œæ›²ä¿¡æ¯
        song_data = generator.extract_mcz_info(input_mcz)
        if not song_data:
            raise ValueError("æ— æ³•è§£æMCZæ–‡ä»¶")
            
        print(f"ğŸ“– æ­Œæ›²ä¿¡æ¯:")
        print(f"   æ ‡é¢˜: {song_data['title']}")
        print(f"   è‰ºæœ¯å®¶: {song_data['artist']}")
        
        # æå–éŸ³é¢‘ç‰¹å¾
        print("ğŸ” æå–éŸ³é¢‘ç‰¹å¾...")
        audio_features = generator.extract_audio_features(song_data['audio_path'])
        
        # ç”Ÿæˆé«˜å¯†åº¦è°±é¢
        print("ğŸ¼ ç”Ÿæˆé«˜å¯†åº¦è°±é¢...")
        mc_data = generator.generate_beatmap_standard_format(
            audio_features, target_difficulty, target_keys, song_data
        )
        
        if mc_data:
            # åˆ›å»ºæ ‡å‡†MCZåŒ…
            success = generator.create_standard_mcz_package(song_data, mc_data, output_mcz)
            
            if success:
                print(f"\nğŸ‰ é«˜å¯†åº¦è°±é¢ç”ŸæˆæˆåŠŸï¼")
                print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_mcz}")
                print(f"ğŸµ æ­Œæ›²: {song_data['title']}")
                print(f"ğŸ¯ éš¾åº¦: {mc_data['meta']['version']}")
                print(f"ğŸ¼ æ€»éŸ³ç¬¦æ•°é‡: {len(mc_data['note'])}")
                print(f"ğŸ® æ¸¸æˆéŸ³ç¬¦æ•°é‡: {len(mc_data['note']) - 1}")
                print(f"ğŸ”§ æ ¼å¼: æ ‡å‡†MCæ ¼å¼ (24åˆ†éŸ³ç¬¦ç²¾åº¦)")
            else:
                print("âŒ MCZåŒ…åˆ›å»ºå¤±è´¥")
        else:
            print("âŒ è°±é¢ç”Ÿæˆå¤±è´¥")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
