#!/usr/bin/env python3
"""
æ”¹è¿›çš„ç²¾ç¡®æ—¶æœºæ ¡å‡†è°±é¢ç”Ÿæˆå™¨
ä¸“æ³¨äºéŸ³é‡å³°å€¼çš„ç²¾ç¡®å®šä½ï¼Œç¡®ä¿éŸ³æ¸¸ä½“éªŒ
"""

import numpy as np
import librosa
import json
import zipfile
import os
from scipy.signal import find_peaks, savgol_filter

def generate_precise_beatmap(audio_path, output_path, target_note_count=1500):
    """ç”Ÿæˆæ—¶æœºç²¾ç¡®æ ¡å‡†çš„è°±é¢"""
    print(f"ğŸ¯ å¼€å§‹ç”Ÿæˆç²¾ç¡®æ—¶æœºæ ¡å‡†çš„è°±é¢...")
    print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶: {os.path.basename(audio_path)}")
    
    # 1. åŠ è½½éŸ³é¢‘
    y, sr = librosa.load(audio_path, sr=22050)
    duration = len(y) / sr
    print(f"â±ï¸ éŸ³é¢‘æ—¶é•¿: {duration:.2f} ç§’")
    
    # 2. ç²¾ç¡®çš„å³°å€¼æ£€æµ‹
    peak_times = detect_audio_peaks(y, sr, target_note_count)
    print(f"ğŸµ æ£€æµ‹åˆ° {len(peak_times)} ä¸ªç²¾ç¡®å³°å€¼")
    
    # 3. æ™ºèƒ½é”®ä½åˆ†é…
    note_data = assign_smart_columns(y, sr, peak_times)
    print(f"ğŸ¹ å®Œæˆé”®ä½åˆ†é…")
    
    # 4. ç”ŸæˆMCZæ–‡ä»¶
    generate_mcz_file(note_data, duration, output_path)
    print(f"âœ… è°±é¢ç”Ÿæˆå®Œæˆ: {output_path}")
    
    # 5. åˆ†æç²¾ç¡®åº¦
    analyze_timing_precision(y, sr, note_data)
    
    return note_data

def detect_audio_peaks(y, sr, target_count):
    """æ£€æµ‹éŸ³é¢‘å³°å€¼ï¼Œç¡®ä¿ç²¾ç¡®æ—¶æœº"""
    print(f"ğŸ” æ­£åœ¨è¿›è¡ŒéŸ³é¢‘å³°å€¼æ£€æµ‹...")
    
    # 1. å¤šåˆ†è¾¨ç‡èƒ½é‡åˆ†æ
    # çŸ­æ—¶èƒ½é‡ (ç”¨äºç²¾ç¡®å®šä½)
    frame_short = int(0.01 * sr)  # 10ms
    hop_short = int(0.005 * sr)   # 5ms
    
    # ä¸­æ—¶èƒ½é‡ (ç”¨äºå³°å€¼æ£€æµ‹)
    frame_med = int(0.05 * sr)    # 50ms
    hop_med = int(0.025 * sr)     # 25ms
    
    # è®¡ç®—RMSèƒ½é‡
    rms_short = librosa.feature.rms(y=y, frame_length=frame_short, hop_length=hop_short)[0]
    rms_med = librosa.feature.rms(y=y, frame_length=frame_med, hop_length=hop_med)[0]
    
    # 2. åŸºäºä¸­ç­‰åˆ†è¾¨ç‡æ£€æµ‹å³°å€¼ä½ç½®
    if len(rms_med) > 5:
        # å¹³æ»‘å¤„ç†
        window_len = min(5, len(rms_med) if len(rms_med) % 2 == 1 else len(rms_med) - 1)
        if window_len >= 3:
            rms_smooth = savgol_filter(rms_med, window_len, 2)
        else:
            rms_smooth = rms_med
    else:
        rms_smooth = rms_med
    
    # 3. è‡ªé€‚åº”é˜ˆå€¼æ£€æµ‹
    rms_mean = np.mean(rms_smooth)
    rms_std = np.std(rms_smooth)
    
    print(f"   RMSç»Ÿè®¡: å‡å€¼={rms_mean:.4f}, æ ‡å‡†å·®={rms_std:.4f}")
    
    # åŠ¨æ€è°ƒæ•´é˜ˆå€¼ç›´åˆ°æ‰¾åˆ°åˆé€‚æ•°é‡çš„å³°å€¼
    thresholds = [
        rms_mean + 1.5 * rms_std,
        rms_mean + rms_std,
        rms_mean + 0.5 * rms_std,
        rms_mean + 0.2 * rms_std,
        rms_mean,
        rms_mean - 0.2 * rms_std
    ]
    
    best_peaks = None
    best_threshold = None
    
    for threshold in thresholds:
        # æœ€å°é—´è·ï¼šç¡®ä¿éŸ³ç¬¦ä¸ä¼šå¤ªå¯†é›†
        min_distance = max(1, int(0.1 * len(rms_smooth)))  # è‡³å°‘100msé—´è·
        
        peaks, properties = find_peaks(
            rms_smooth,
            height=threshold,
            distance=min_distance,
            prominence=rms_std * 0.05
        )
        
        print(f"   é˜ˆå€¼ {threshold:.4f}: æ‰¾åˆ° {len(peaks)} ä¸ªå³°å€¼")
        
        # é€‰æ‹©æœ€æ¥è¿‘ç›®æ ‡æ•°é‡çš„é˜ˆå€¼
        if len(peaks) >= target_count * 0.5:  # è‡³å°‘è¦æœ‰ç›®æ ‡æ•°é‡çš„ä¸€åŠ
            best_peaks = peaks
            best_threshold = threshold
            if len(peaks) <= target_count * 1.2:  # ä¸è¦è¶…è¿‡å¤ªå¤š
                break
    
    if best_peaks is None or len(best_peaks) < 10:
        print(f"   âš ï¸ å³°å€¼å¤ªå°‘ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ...")
        # å¤‡é€‰æ–¹æ¡ˆï¼šæ›´ä½çš„é˜ˆå€¼
        min_threshold = rms_mean - rms_std
        min_distance = max(1, int(0.05 * len(rms_smooth)))  # 50msé—´è·
        
        peaks, _ = find_peaks(
            rms_smooth,
            height=min_threshold,
            distance=min_distance
        )
        best_peaks = peaks
        best_threshold = min_threshold
        print(f"   å¤‡é€‰é˜ˆå€¼ {best_threshold:.4f}: æ‰¾åˆ° {len(peaks)} ä¸ªå³°å€¼")
    
    # 4. è½¬æ¢åˆ°ç²¾ç¡®æ—¶é—´ä½ç½®
    precise_peaks = []
    
    for peak_idx in best_peaks:
        # è½¬æ¢åˆ°æ—¶é—´
        rough_time = peak_idx * hop_med / sr
        
        # åœ¨é«˜åˆ†è¾¨ç‡æ•°æ®ä¸­å¯»æ‰¾ç²¾ç¡®ä½ç½®
        search_start = max(0, int((rough_time - 0.05) * sr / hop_short))
        search_end = min(len(rms_short), int((rough_time + 0.05) * sr / hop_short))
        
        if search_start < search_end:
            local_rms = rms_short[search_start:search_end]
            if len(local_rms) > 0:
                local_peak_idx = np.argmax(local_rms)
                precise_time = (search_start + local_peak_idx) * hop_short / sr
                precise_peaks.append(precise_time)
        else:
            precise_peaks.append(rough_time)
    
    # 5. è¿›ä¸€æ­¥åœ¨åŸå§‹ä¿¡å·ä¸­ç²¾ç¡®å®šä½
    final_peaks = []
    for peak_time in precise_peaks:
        # åœ¨åŸå§‹ä¿¡å·ä¸­å¯»æ‰¾Â±10msèŒƒå›´å†…çš„çœŸæ­£å³°å€¼
        center_sample = int(peak_time * sr)
        search_range = int(0.01 * sr)  # 10msæœç´¢èŒƒå›´
        
        start_sample = max(0, center_sample - search_range)
        end_sample = min(len(y), center_sample + search_range)
        
        if start_sample < end_sample:
            local_audio = np.abs(y[start_sample:end_sample])
            if len(local_audio) > 0:
                local_max_idx = np.argmax(local_audio)
                exact_time = (start_sample + local_max_idx) / sr
                final_peaks.append(exact_time)
    
    # 6. å¦‚æœæ•°é‡ä¸å¤Ÿï¼Œè¡¥å……æ›´å¤šå³°å€¼
    if len(final_peaks) < target_count * 0.7:
        print(f"   ğŸ“ˆ å³°å€¼æ•°é‡ä¸è¶³ï¼Œè¡¥å……æ›´å¤š...")
        # ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼è·å–æ›´å¤šå³°å€¼
        additional_threshold = best_threshold * 0.7
        min_distance = max(1, int(0.03 * len(rms_smooth)))  # 30msé—´è·
        
        additional_peaks, _ = find_peaks(
            rms_smooth,
            height=additional_threshold,
            distance=min_distance
        )
        
        for peak_idx in additional_peaks:
            peak_time = peak_idx * hop_med / sr
            # é¿å…é‡å¤
            if not any(abs(peak_time - existing) < 0.05 for existing in final_peaks):
                final_peaks.append(peak_time)
                if len(final_peaks) >= target_count:
                    break
    
    # 7. å¦‚æœè¿˜æ˜¯å¤ªå°‘ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒè¡¥å……
    if len(final_peaks) < target_count * 0.5:
        print(f"   âš¡ ä½¿ç”¨æ™ºèƒ½è¡¥å……...")
        # åˆ†æéŸ³é¢‘æ´»è·ƒåŒºåŸŸ
        audio_active = np.abs(y) > np.mean(np.abs(y)) * 0.3
        active_segments = []
        
        # æ‰¾åˆ°è¿ç»­çš„æ´»è·ƒæ®µ
        in_segment = False
        segment_start = 0
        
        for i, is_active in enumerate(audio_active):
            if is_active and not in_segment:
                segment_start = i
                in_segment = True
            elif not is_active and in_segment:
                segment_end = i
                if segment_end - segment_start > sr * 0.5:  # è‡³å°‘0.5ç§’çš„æ®µ
                    active_segments.append((segment_start / sr, segment_end / sr))
                in_segment = False
        
        # åœ¨æ´»è·ƒæ®µä¸­å‡åŒ€æ·»åŠ éŸ³ç¬¦
        needed = target_count - len(final_peaks)
        if active_segments and needed > 0:
            notes_per_segment = needed // len(active_segments)
            for start_time, end_time in active_segments:
                segment_duration = end_time - start_time
                if segment_duration > 1.0:  # è‡³å°‘1ç§’
                    for i in range(notes_per_segment):
                        note_time = start_time + (i + 1) * segment_duration / (notes_per_segment + 1)
                        # é¿å…é‡å¤
                        if not any(abs(note_time - existing) < 0.1 for existing in final_peaks):
                            final_peaks.append(note_time)
    
    # 8. é™åˆ¶æ•°é‡å¹¶æ’åº
    if len(final_peaks) > target_count:
        # æŒ‰éŸ³é‡å¼ºåº¦æ’åºï¼Œé€‰æ‹©æœ€å¼ºçš„
        peak_strengths = []
        for peak_time in final_peaks:
            sample_idx = int(peak_time * sr)
            if 0 <= sample_idx < len(y):
                strength = abs(y[sample_idx])
                peak_strengths.append((peak_time, strength))
        
        peak_strengths.sort(key=lambda x: x[1], reverse=True)
        final_peaks = [pt[0] for pt in peak_strengths[:target_count]]
    
    # æŒ‰æ—¶é—´æ’åº
    final_peaks = sorted(final_peaks)
    
    print(f"âœ… æœ€ç»ˆæ£€æµ‹åˆ° {len(final_peaks)} ä¸ªç²¾ç¡®å³°å€¼")
    if final_peaks:
        print(f"   æ—¶é—´èŒƒå›´: {final_peaks[0]:.3f} - {final_peaks[-1]:.3f} ç§’")
    
    return np.array(final_peaks)

def assign_smart_columns(y, sr, peak_times):
    """æ™ºèƒ½åˆ†é…é”®ä½"""
    print(f"ğŸ¹ å¼€å§‹æ™ºèƒ½é”®ä½åˆ†é…...")
    
    note_data = []
    
    for i, peak_time in enumerate(peak_times):
        # è®¡ç®—éŸ³é¢‘ç‰¹å¾
        sample_idx = int(peak_time * sr)
        window_size = int(0.025 * sr)  # 25msçª—å£
        
        start_idx = max(0, sample_idx - window_size)
        end_idx = min(len(y), sample_idx + window_size)
        audio_window = y[start_idx:end_idx]
        
        if len(audio_window) > 0:
            # è®¡ç®—é¢‘ç‡ç‰¹å¾
            fft = np.fft.fft(audio_window)
            magnitude = np.abs(fft)
            freqs = np.fft.fftfreq(len(fft), 1/sr)
            
            positive_freqs = freqs[:len(freqs)//2]
            positive_magnitude = magnitude[:len(magnitude)//2]
            
            if np.sum(positive_magnitude) > 0:
                spectral_centroid = np.sum(positive_freqs * positive_magnitude) / np.sum(positive_magnitude)
            else:
                spectral_centroid = 1000
            
            # åŸºäºé¢‘ç‡é€‰æ‹©é”®ä½
            if spectral_centroid < 400:
                base_column = 0
            elif spectral_centroid < 800:
                base_column = 1
            elif spectral_centroid < 1500:
                base_column = 2
            else:
                base_column = 3
            
            # æ·»åŠ ä¸€äº›éšæœºæ€§é¿å…å•è°ƒ
            if np.random.random() < 0.2:
                base_column = (base_column + np.random.randint(-1, 2)) % 4
            
        else:
            base_column = i % 4
        
        note_data.append({
            'time': peak_time,
            'column': base_column
        })
    
    # åå¤„ç†ï¼šå¹³è¡¡é”®ä½åˆ†å¸ƒ
    columns = [note['column'] for note in note_data]
    column_counts = [columns.count(i) for i in range(4)]
    
    print(f"   é”®ä½åˆ†å¸ƒ: {column_counts}")
    
    # å¦‚æœæŸä¸ªé”®ä½å¤ªå°‘ï¼Œè°ƒæ•´ä¸€äº›éŸ³ç¬¦
    min_count = len(note_data) // 8  # æ¯ä¸ªé”®ä½è‡³å°‘12.5%
    for col in range(4):
        if column_counts[col] < min_count:
            needed = min_count - column_counts[col]
            # ä»ä½¿ç”¨æœ€å¤šçš„é”®ä½å€Ÿä¸€äº›
            max_col = column_counts.index(max(column_counts))
            changed = 0
            for note in note_data:
                if note['column'] == max_col and changed < needed:
                    note['column'] = col
                    changed += 1
                    if changed >= needed:
                        break
    
    print(f"âœ… é”®ä½åˆ†é…å®Œæˆ")
    return note_data

def generate_mcz_file(note_data, duration, output_path):
    """ç”ŸæˆMCZæ–‡ä»¶"""
    print(f"ğŸ“¦ ç”ŸæˆMCZæ–‡ä»¶...")
    
    # è®¾ç½®å‚æ•°
    bpm = 156
    subdivision = 24
    
    # å‡†å¤‡éŸ³ç¬¦æ•°æ®
    mc_notes = []
    
    # éŸ³é¢‘æ§åˆ¶
    mc_notes.extend([
        {"beat": [0, 0, 24], "endbeat": [0, 0, 24], "sound": "kawaki.ogg"},
        {"beat": [int(duration * bpm / 60), 0, 24], "endbeat": [int(duration * bpm / 60), 0, 24], "sound": ""}
    ])
    
    # æ¸¸æˆéŸ³ç¬¦
    for note in note_data:
        beat_value = note['time'] * bpm / 60
        x = int(beat_value)
        y = int((beat_value % 1) * subdivision)
        
        mc_notes.append({
            "beat": [x, y, 24],
            "endbeat": [x, y, 24],
            "column": int(note['column'])
        })
    
    # MCæ•°æ®ç»“æ„
    mc_data = {
        "meta": {
            "version": "4.0.0",
            "mode": "0",
            "time": int(duration * 1000),
            "song": {
                "title": "Precise Generated Beatmap",
                "artist": "AI Generator (Precise)",
                "id": 4833
            },
            "mode_ext": {
                "column": 4
            }
        },
        "time": [
            {
                "beat": [0, 0, 24],
                "bpm": 156.0
            }
        ],
        "note": mc_notes
    }
    
    # åˆ›å»ºMCZæ–‡ä»¶
    import tempfile
    import shutil
    
    with tempfile.TemporaryDirectory() as temp_dir:
        beat_dir = os.path.join(temp_dir, "0")
        os.makedirs(beat_dir)
        
        # å†™å…¥MCæ–‡ä»¶
        mc_file_path = os.path.join(beat_dir, "1511697495.mc")
        with open(mc_file_path, 'w', encoding='utf-8') as f:
            json.dump(mc_data, f, separators=(',', ':'))
        
        # åˆ›å»ºZIP
        shutil.make_archive(output_path.replace('.mcz', ''), 'zip', temp_dir)
        if os.path.exists(output_path.replace('.mcz', '') + '.zip'):
            os.rename(output_path.replace('.mcz', '') + '.zip', output_path)

def analyze_timing_precision(y, sr, note_data):
    """åˆ†ææ—¶æœºç²¾ç¡®åº¦"""
    print(f"\nğŸ¯ æ—¶æœºç²¾ç¡®åº¦åˆ†æ:")
    
    precisions = []
    for note in note_data:
        peak_time = note['time']
        sample_idx = int(peak_time * sr)
        
        # æ£€æŸ¥Â±5msèŒƒå›´å†…çš„çœŸå®å³°å€¼ä½ç½®
        search_range = int(0.005 * sr)
        start_idx = max(0, sample_idx - search_range)
        end_idx = min(len(y), sample_idx + search_range)
        
        if start_idx < end_idx:
            local_audio = np.abs(y[start_idx:end_idx])
            true_peak_idx = np.argmax(local_audio)
            true_peak_sample = start_idx + true_peak_idx
            
            error_samples = abs(sample_idx - true_peak_sample)
            error_ms = error_samples / sr * 1000
            precisions.append(error_ms)
    
    if precisions:
        avg_error = np.mean(precisions)
        max_error = np.max(precisions)
        
        print(f"   å¹³å‡è¯¯å·®: {avg_error:.2f} ms")
        print(f"   æœ€å¤§è¯¯å·®: {max_error:.2f} ms")
        print(f"   95%éŸ³ç¬¦è¯¯å·®å°äº: {np.percentile(precisions, 95):.2f} ms")
        
        if avg_error < 10:
            print(f"   ğŸŸ¢ ç²¾ç¡®åº¦è¯„ä»·: ä¼˜ç§€ (Â±{avg_error:.1f}ms)")
        elif avg_error < 20:
            print(f"   ğŸŸ¡ ç²¾ç¡®åº¦è¯„ä»·: è‰¯å¥½ (Â±{avg_error:.1f}ms)")
        else:
            print(f"   ğŸ”´ ç²¾ç¡®åº¦è¯„ä»·: éœ€æ”¹è¿› (Â±{avg_error:.1f}ms)")

if __name__ == "__main__":
    # ä½¿ç”¨ç°æœ‰éŸ³é¢‘æ–‡ä»¶æµ‹è¯•
    audio_file = "extracted_audio\_song_10088_Kawaki wo Ameku.ogg"
    output_file = "precise_beatmap.mcz"
    
    if os.path.exists(audio_file):
        print(f"ğŸµ ä½¿ç”¨éŸ³é¢‘æ–‡ä»¶: {audio_file}")
        note_data = generate_precise_beatmap(audio_file, output_file, target_note_count=1200)
        
        print(f"\nğŸ® ç²¾ç¡®è°±é¢ç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“‚ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"ğŸµ éŸ³ç¬¦æ•°é‡: {len(note_data)}")
        print(f"ğŸ¯ ç‰¹ç‚¹: éŸ³ç¬¦ç²¾ç¡®å¯¹å‡†éŸ³é‡å³°å€¼ï¼Œæœ€å°åŒ–æ—¶æœºè¯¯å·®")
    else:
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        print(f"è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„")
