#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
import sys
import os
# ä¿®å¤å·¥ä½œåŒºé‡ç»„åçš„å¯¼å…¥è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)


ä¿®å¤æ‰€æœ‰Pythonæ–‡ä»¶çš„å¯¼å…¥é—®é¢˜
æ•´ç†å·¥ä½œåŒºåçš„å¯¼å…¥è·¯å¾„ä¿®å¤å·¥å…·
"""

import os
import re
from typing import List, Dict

class ImportFixer:
    """å¯¼å…¥ä¿®å¤å™¨"""
    
    def __init__(self):
        self.base_dir = "d:/Projects/FumenGenerate"
        
        # å®šä¹‰æ–‡ä»¶çš„æ–°ä½ç½®æ˜ å°„
        self.file_locations = {
            # æ ¸å¿ƒæ¨¡å—åœ¨ core/ ç›®å½•
            'mcz_parser': 'core.mcz_parser',
            'four_k_extractor': 'core.four_k_extractor', 
            'audio_beatmap_analyzer': 'core.audio_beatmap_analyzer',
            'audio_extractor': 'core.audio_extractor',
            'data_processor': 'core.data_processor',
            
            # å­¦ä¹ ç³»ç»Ÿåœ¨æ ¹ç›®å½•ï¼ˆéœ€è¦ç§»åŠ¨åˆ°scriptsï¼‰
            'beatmap_learning_system': 'scripts.beatmap_learning_system',
            'deep_learning_beatmap_system': 'scripts.deep_learning_beatmap_system',
            'hybrid_beatmap_system': 'scripts.hybrid_beatmap_system',
        }
        
        # éœ€è¦ä¿®å¤çš„æ–‡ä»¶åˆ—è¡¨
        self.files_to_fix = [
            'large_scale_real_training.py',
            'scripts/quick_hybrid_train.py', 
            'scripts/test_deep_learning.py',
            'scripts/final_demo.py',
            'scripts/large_scale_training.py',
            'batch_analyzer.py',
            'quick_demo.py',
            'quick_test.py',
        ]
    
    def find_missing_files(self):
        """æŸ¥æ‰¾ç¼ºå¤±çš„æ–‡ä»¶"""
        print("ğŸ” æŸ¥æ‰¾éœ€è¦ç§»åŠ¨çš„æ–‡ä»¶...")
        
        # æŸ¥æ‰¾å­¦ä¹ ç³»ç»Ÿæ–‡ä»¶
        learning_files = [
            'beatmap_learning_system.py',
            'deep_learning_beatmap_system.py', 
            'hybrid_beatmap_system.py'
        ]
        
        for file in learning_files:
            if os.path.exists(file):
                print(f"ğŸ“ å‘ç°æ–‡ä»¶: {file} -> éœ€è¦ç§»åŠ¨åˆ° scripts/")
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file}")
    
    def move_files_to_scripts(self):
        """ç§»åŠ¨å­¦ä¹ ç³»ç»Ÿæ–‡ä»¶åˆ°scriptsç›®å½•"""
        os.makedirs('scripts', exist_ok=True)
        
        learning_files = [
            'beatmap_learning_system.py',
            'deep_learning_beatmap_system.py', 
            'hybrid_beatmap_system.py'
        ]
        
        for file in learning_files:
            if os.path.exists(file):
                import shutil
                shutil.move(file, f'scripts/{file}')
                print(f"ğŸ“¦ ç§»åŠ¨: {file} -> scripts/{file}")
    
    def fix_imports_in_file(self, file_path: str):
        """ä¿®å¤å•ä¸ªæ–‡ä»¶çš„å¯¼å…¥"""
        if not os.path.exists(file_path):
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return
        
        print(f"ğŸ”§ ä¿®å¤å¯¼å…¥: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            
            # ä¿®å¤å„ç§å¯¼å…¥æ¨¡å¼
            for old_import, new_import in self.file_locations.items():
                # ä¿®å¤ from xxx import 
                pattern1 = f"from {old_import} import"
                replacement1 = f"from {new_import} import"
                content = re.sub(pattern1, replacement1, content)
                
                # ä¿®å¤ import xxx
                pattern2 = f"import {old_import}"
                replacement2 = f"import {new_import}"
                content = re.sub(pattern2, replacement2, content)
                
                # ä¿®å¤ from xxx.yyy import
                pattern3 = f"from {old_import}\\."
                replacement3 = f"from {new_import}."
                content = re.sub(pattern3, replacement3, content)
            
            # å¦‚æœå†…å®¹æœ‰å˜åŒ–ï¼Œå†™å›æ–‡ä»¶
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"  âœ… ä¿®å¤å®Œæˆ")
            else:
                print(f"  â„¹ï¸  æ— éœ€ä¿®å¤")
                
        except Exception as e:
            print(f"  âŒ ä¿®å¤å¤±è´¥: {e}")
    
    def fix_all_imports(self):
        """ä¿®å¤æ‰€æœ‰æ–‡ä»¶çš„å¯¼å…¥"""
        print("ğŸš€ å¼€å§‹ä¿®å¤æ‰€æœ‰å¯¼å…¥é—®é¢˜...")
        
        # é¦–å…ˆç§»åŠ¨æ–‡ä»¶
        self.move_files_to_scripts()
        
        # ä¿®å¤æ¯ä¸ªæ–‡ä»¶çš„å¯¼å…¥
        for file_path in self.files_to_fix:
            self.fix_imports_in_file(file_path)
        
        print("âœ… å¯¼å…¥ä¿®å¤å®Œæˆï¼")
    
    def create_working_training_script(self):
        """åˆ›å»ºä¸€ä¸ªèƒ½æ­£å¸¸å·¥ä½œçš„è®­ç»ƒè„šæœ¬"""
        script_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å·¥ä½œç›®å½•ä¿®å¤åçš„å¿«é€Ÿè®­ç»ƒè„šæœ¬
"""

import os
import sys
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torch.nn.functional as F
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥
sys.path.append('.')
sys.path.append('core')
sys.path.append('scripts')

def load_existing_data():
    """åŠ è½½ç°æœ‰çš„è®­ç»ƒæ•°æ®"""
    try:
        from scripts.beatmap_learning_system import BeatmapLearningSystem
        
        print("ğŸ“¥ åŠ è½½ç°æœ‰è®­ç»ƒæ•°æ®...")
        system = BeatmapLearningSystem()
        aligned_datasets = system.collect_training_data('test_4k_beatmaps.json', 'extracted_audio')
        
        if not aligned_datasets:
            print("âŒ æ— æ³•åŠ è½½æ•°æ®")
            return None, None
        
        X, y_note, y_column, y_long = system.prepare_machine_learning_data(aligned_datasets)
        return X, y_note
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None, None

class QuickHybridNet(nn.Module):
    """å¿«é€Ÿæ··åˆç½‘ç»œ"""
    
    def __init__(self, input_dim):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        return self.network(x).squeeze()

def quick_train():
    """å¿«é€Ÿè®­ç»ƒ"""
    print("ğŸš€ å¿«é€Ÿæ··åˆè®­ç»ƒ")
    print("=" * 40)
    
    # åŠ è½½æ•°æ®
    X, y = load_existing_data()
    if X is None:
        print("âŒ æ— æ³•è·å–è®­ç»ƒæ•°æ®")
        return
    
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(X):,} æ ·æœ¬")
    
    # è®­ç»ƒRF
    print("ğŸŒ² è®­ç»ƒéšæœºæ£®æ—...")
    rf = RandomForestClassifier(n_estimators=50, random_state=42)
    rf.fit(X, y)
    rf_probs = rf.predict_proba(X)[:, 1]
    
    # æ„å»ºå¢å¼ºç‰¹å¾
    enhanced_X = np.column_stack([X, rf_probs, np.gradient(rf_probs)])
    
    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    enhanced_X = scaler.fit_transform(enhanced_X)
    
    # åˆ†å‰²æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(
        enhanced_X, y, test_size=0.2, random_state=42
    )
    
    # è®­ç»ƒç¥ç»ç½‘ç»œ
    print("ğŸ§  è®­ç»ƒç¥ç»ç½‘ç»œ...")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    model = QuickHybridNet(enhanced_X.shape[1]).to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.BCELoss()
    
    # è½¬æ¢æ•°æ®
    X_train_tensor = torch.FloatTensor(X_train).to(device)
    y_train_tensor = torch.FloatTensor(y_train).to(device)
    X_test_tensor = torch.FloatTensor(X_test).to(device)
    y_test_tensor = torch.FloatTensor(y_test).to(device)
    
    # è®­ç»ƒ
    for epoch in range(20):
        model.train()
        optimizer.zero_grad()
        outputs = model(X_train_tensor)
        loss = criterion(outputs, y_train_tensor)
        loss.backward()
        optimizer.step()
        
        if epoch % 5 == 0:
            model.eval()
            with torch.no_grad():
                test_outputs = model(X_test_tensor)
                test_pred = (test_outputs > 0.5).float()
                accuracy = (test_pred == y_test_tensor).float().mean()
                print(f"Epoch {epoch}: æŸå¤±={loss:.4f}, å‡†ç¡®ç‡={accuracy:.3f}")
    
    # æœ€ç»ˆæµ‹è¯•
    model.eval()
    with torch.no_grad():
        final_outputs = model(X_test_tensor)
        final_pred = (final_outputs > 0.5).float()
        final_accuracy = (final_pred == y_test_tensor).float().mean()
        
        rf_acc = rf.score(X_test[:, :X.shape[1]], y_test)
    
    print(f"\\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸŒ² éšæœºæ£®æ—å‡†ç¡®ç‡: {rf_acc:.3f}")
    print(f"ğŸ§  æ··åˆæ¨¡å‹å‡†ç¡®ç‡: {final_accuracy:.3f}")
    print(f"ğŸ“ˆ æå‡: {final_accuracy - rf_acc:.3f}")
    
    # ä¿å­˜æ¨¡å‹
    os.makedirs('models', exist_ok=True)
    torch.save({
        'model_state_dict': model.state_dict(),
        'accuracy': final_accuracy.item()
    }, 'models/working_hybrid_model.pth')
    
    import pickle
    with open('models/working_components.pkl', 'wb') as f:
        pickle.dump({'rf': rf, 'scaler': scaler}, f)
    
    print("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ° models/")

if __name__ == "__main__":
    quick_train()
'''
        
        with open('working_train.py', 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        print("ğŸ“ åˆ›å»ºäº† working_train.py - ä¿®å¤å¯¼å…¥é—®é¢˜çš„è®­ç»ƒè„šæœ¬")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ Pythonå·¥ä½œåŒºå¯¼å…¥ä¿®å¤å·¥å…·")
    print("=" * 50)
    
    fixer = ImportFixer()
    
    # æŸ¥æ‰¾æ–‡ä»¶
    fixer.find_missing_files()
    
    # ä¿®å¤å¯¼å…¥
    fixer.fix_all_imports()
    
    # åˆ›å»ºå·¥ä½œè„šæœ¬
    fixer.create_working_training_script()
    
    print("\\nâœ… ä¿®å¤å®Œæˆï¼ç°åœ¨å¯ä»¥è¿è¡Œ:")
    print("   python working_train.py")

if __name__ == "__main__":
    main()
