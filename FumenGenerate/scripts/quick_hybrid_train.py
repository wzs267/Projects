#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®é™…è®­ç»ƒæ··åˆç³»ç»Ÿ
ä½¿ç”¨çœŸå®æ•°æ®å¿«é€Ÿè®­ç»ƒå’Œæµ‹è¯•
"""

import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

def quick_train_hybrid():
    """å¿«é€Ÿè®­ç»ƒæ··åˆç³»ç»Ÿ"""
    print("ğŸš€ å¿«é€Ÿè®­ç»ƒæ··åˆå­¦ä¹ ç³»ç»Ÿ")
    print("=" * 50)
    
    # åŠ è½½ç°æœ‰è®­ç»ƒæ•°æ®
    try:
        from scripts.beatmap_learning_system import BeatmapLearningSystem
        
        print("ğŸ“¥ åŠ è½½è®­ç»ƒæ•°æ®...")
        system = BeatmapLearningSystem()
        aligned_datasets = system.collect_training_data('test_4k_beatmaps.json', 'extracted_audio')
        
        if not aligned_datasets:
            print("âŒ æ— æ³•åŠ è½½æ•°æ®")
            return
        
        X, y_note, y_column, y_long = system.prepare_machine_learning_data(aligned_datasets)
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(X):,} ä¸ªæ ·æœ¬")
        
        # 1. è®­ç»ƒéšæœºæ£®æ—è·å–ç‰¹å¾é‡è¦æ€§
        print("\nğŸŒ² è®­ç»ƒéšæœºæ£®æ—ç‰¹å¾æå–å™¨...")
        rf_model = RandomForestClassifier(n_estimators=50, random_state=42)
        rf_model.fit(X, y_note)
        
        # è·å–ç‰¹å¾é‡è¦æ€§æ’åº
        feature_importance = rf_model.feature_importances_
        rf_probs = rf_model.predict_proba(X)[:, 1]  # éŸ³ç¬¦æ¦‚ç‡
        
        print(f"ğŸ¯ RFå‡†ç¡®ç‡: {rf_model.score(X, y_note):.3f}")
        
        # 2. æ„å»ºå¢å¼ºç‰¹å¾
        enhanced_features = np.column_stack([
            X,  # åŸå§‹éŸ³é¢‘ç‰¹å¾
            rf_probs,  # RFéŸ³ç¬¦æ¦‚ç‡
            feature_importance.reshape(1, -1).repeat(len(X), axis=0),  # ç‰¹å¾é‡è¦æ€§æƒé‡
            np.gradient(rf_probs),  # RFæ¦‚ç‡æ¢¯åº¦
        ])
        
        print(f"ğŸ“Š å¢å¼ºç‰¹å¾ç»´åº¦: {X.shape[1]} â†’ {enhanced_features.shape[1]}")
        
        # 3. ç®€åŒ–ç¥ç»ç½‘ç»œ
        class SimpleHybridNet(nn.Module):
            def __init__(self, input_dim):
                super().__init__()
                self.network = nn.Sequential(
                    nn.Linear(input_dim, 128),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(128, 64),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(64, 32),
                    nn.ReLU(),
                    nn.Linear(32, 1),
                    nn.Sigmoid()
                )
            
            def forward(self, x):
                return self.network(x).squeeze()
        
        # 4. è®­ç»ƒæ··åˆæ¨¡å‹
        print("\nğŸ§  è®­ç»ƒæ··åˆç¥ç»ç½‘ç»œ...")
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"è®¾å¤‡: {device}")
        
        # æ•°æ®å‡†å¤‡
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(enhanced_features)
        
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y_note, test_size=0.2, random_state=42
        )
        
        # è½¬æ¢ä¸ºTensor
        X_train_tensor = torch.FloatTensor(X_train).to(device)
        y_train_tensor = torch.FloatTensor(y_train).to(device)
        X_test_tensor = torch.FloatTensor(X_test).to(device)
        y_test_tensor = torch.FloatTensor(y_test).to(device)
        
        # åˆ›å»ºæ¨¡å‹
        model = SimpleHybridNet(enhanced_features.shape[1]).to(device)
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.BCELoss()
        
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()):,}")
        
        # è®­ç»ƒ
        model.train()
        for epoch in range(20):  # å¿«é€Ÿè®­ç»ƒ20è½®
            optimizer.zero_grad()
            outputs = model(X_train_tensor)
            loss = criterion(outputs, y_train_tensor)
            loss.backward()
            optimizer.step()
            
            if epoch % 5 == 0:
                # éªŒè¯
                model.eval()
                with torch.no_grad():
                    test_outputs = model(X_test_tensor)
                    test_loss = criterion(test_outputs, y_test_tensor)
                    
                    # è®¡ç®—å‡†ç¡®ç‡
                    test_pred = (test_outputs > 0.5).float()
                    accuracy = (test_pred == y_test_tensor).float().mean()
                    
                print(f"Epoch {epoch:2d}: è®­ç»ƒæŸå¤±={loss:.4f}, æµ‹è¯•æŸå¤±={test_loss:.4f}, å‡†ç¡®ç‡={accuracy:.3f}")
                model.train()
        
        # æœ€ç»ˆæµ‹è¯•
        model.eval()
        with torch.no_grad():
            final_outputs = model(X_test_tensor)
            final_pred = (final_outputs > 0.5).float()
            final_accuracy = (final_pred == y_test_tensor).float().mean()
            
            # ä¸RFå¯¹æ¯”ï¼ˆä½¿ç”¨åŸå§‹ç‰¹å¾ï¼‰
            rf_test_probs = rf_model.predict_proba(X_test[:, :X.shape[1]])[:, 1]  # åªç”¨åŸå§‹ç‰¹å¾
            rf_test_pred = (rf_test_probs > 0.5).astype(float)
            rf_accuracy = (rf_test_pred == y_test).mean()
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸŒ² éšæœºæ£®æ—å‡†ç¡®ç‡: {rf_accuracy:.3f}")
        print(f"ğŸ§  æ··åˆç¥ç»ç½‘ç»œå‡†ç¡®ç‡: {final_accuracy:.3f}")
        print(f"ğŸ“ˆ æå‡å¹…åº¦: {(final_accuracy - rf_accuracy):.3f}")
        
        # ä¿å­˜æ¨¡å‹
        torch.save({
            'model_state_dict': model.state_dict(),
            'accuracy': final_accuracy.item()
        }, 'quick_hybrid_model.pth')
        
        # å•ç‹¬ä¿å­˜å…¶ä»–ç»„ä»¶
        import pickle
        with open('hybrid_components.pkl', 'wb') as f:
            pickle.dump({
                'scaler': scaler,
                'rf_model': rf_model
            }, f)
        
        print("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: quick_hybrid_model.pth")
        
        # ç‰¹å¾é‡è¦æ€§åˆ†æ
        print(f"\nğŸ” ç‰¹å¾é‡è¦æ€§Top5:")
        feature_names = [f"éŸ³é¢‘ç‰¹å¾{i}" for i in range(X.shape[1])] + ['RFæ¦‚ç‡', 'RFé‡è¦æ€§æƒé‡', 'RFæ¦‚ç‡æ¢¯åº¦']
        importance_idx = np.argsort(feature_importance)[::-1][:5]
        for i, idx in enumerate(importance_idx):
            if idx < len(feature_names):
                print(f"   {i+1}. {feature_names[idx]}: {feature_importance[idx]:.4f}")
        
        return model, scaler, rf_model
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def demo_generation():
    """æ¼”ç¤ºç”Ÿæˆæ•ˆæœ"""
    if not os.path.exists('quick_hybrid_model.pth'):
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
        return
    
    print("\nğŸ® æ¼”ç¤ºæ··åˆç³»ç»Ÿç”Ÿæˆæ•ˆæœ")
    
    # åŠ è½½æ¨¡å‹
    checkpoint = torch.load('quick_hybrid_model.pth', map_location='cpu', weights_only=False)
    
    # åŠ è½½å…¶ä»–ç»„ä»¶
    import pickle
    with open('hybrid_components.pkl', 'rb') as f:
        components = pickle.load(f)
    
    scaler = components['scaler']
    rf_model = components['rf_model']
    
    print(f"ğŸ“¥ åŠ è½½æ¨¡å‹ (å‡†ç¡®ç‡: {checkpoint['accuracy']:.3f})")
    
    # æ¨¡æ‹ŸéŸ³é¢‘ç‰¹å¾è¿›è¡Œæµ‹è¯•
    print("ğŸµ æ¨¡æ‹ŸéŸ³é¢‘ç‰¹å¾æµ‹è¯•...")
    
    # ç”Ÿæˆä¸€äº›æµ‹è¯•ç‰¹å¾
    test_features = np.random.randn(100, 15)  # æ¨¡æ‹Ÿ100ä¸ªæ—¶é—´æ­¥çš„éŸ³é¢‘ç‰¹å¾
    
    # ä½¿ç”¨RFæ¨¡å‹è·å–æ¦‚ç‡
    rf_probs = rf_model.predict_proba(test_features)[:, 1]
    
    # æ„å»ºå¢å¼ºç‰¹å¾
    feature_importance = rf_model.feature_importances_
    enhanced_test = np.column_stack([
        test_features,
        rf_probs,
        feature_importance.reshape(1, -1).repeat(len(test_features), axis=0),
        np.gradient(rf_probs),
    ])
    
    # æ ‡å‡†åŒ–
    test_scaled = scaler.transform(enhanced_test)
    
    # åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡
    class SimpleHybridNet(nn.Module):
        def __init__(self, input_dim):
            super().__init__()
            self.network = nn.Sequential(
                nn.Linear(input_dim, 128),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(128, 64),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, 1),
                nn.Sigmoid()
            )
        
        def forward(self, x):
            return self.network(x).squeeze()
    
    model = SimpleHybridNet(enhanced_test.shape[1])
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    with torch.no_grad():
        predictions = model(torch.FloatTensor(test_scaled))
        note_predictions = (predictions > 0.5).float().numpy()
    
    print(f"ğŸ¯ é¢„æµ‹ç»“æœ: {np.sum(note_predictions):.0f}/100 ä¸ªä½ç½®æ”¾ç½®éŸ³ç¬¦")
    print(f"ğŸ“Š éŸ³ç¬¦å¯†åº¦: {np.sum(note_predictions)/100:.2f}")
    
    # æ˜¾ç¤ºé¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
    prob_high = np.sum(predictions.numpy() > 0.7)
    prob_medium = np.sum((predictions.numpy() > 0.3) & (predictions.numpy() <= 0.7))
    prob_low = np.sum(predictions.numpy() <= 0.3)
    
    print(f"ğŸ¼ ç½®ä¿¡åº¦åˆ†å¸ƒ:")
    print(f"   é«˜ç½®ä¿¡(>0.7): {prob_high} ä¸ª")
    print(f"   ä¸­ç½®ä¿¡(0.3-0.7): {prob_medium} ä¸ª") 
    print(f"   ä½ç½®ä¿¡(<0.3): {prob_low} ä¸ª")

if __name__ == "__main__":
    # è®­ç»ƒæ··åˆç³»ç»Ÿ
    result = quick_train_hybrid()
    
    if result:
        print("\n" + "="*50)
        # æ¼”ç¤ºç”Ÿæˆæ•ˆæœ
        demo_generation()
    else:
        print("âŒ è®­ç»ƒå¤±è´¥ï¼Œæ— æ³•æ¼”ç¤º")
